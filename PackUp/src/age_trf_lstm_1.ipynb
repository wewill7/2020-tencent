{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train_semi_final/'\n",
    "test_root = './data/test/'\n",
    "# ad = pd.read_csv(train_root+'ad.csv')\n",
    "# click_log = pd.read_csv(train_root +'click_log.csv')\n",
    "# user = pd.read_csv(train_root+'user.csv')\n",
    "# Tclick_log = pd.read_csv(test_root +'click_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445721 4445721\n",
      "110810 110810\n"
     ]
    }
   ],
   "source": [
    "pre_embedding_cre = np.load(train_root+'creative_id_w2v_300d_f.npy')\n",
    "pre_vocab_cre = json.load(open(train_root+'creative_id_vocab_300d_f.json','r'))\n",
    "pre_vocab_cre.update({'_PAD_':len(pre_vocab_cre)})\n",
    "pre_embedding_cre = np.concatenate((pre_embedding_cre,np.zeros((1,300)) ))\n",
    "print(len(pre_embedding_cre),len(pre_vocab_cre))\n",
    "\n",
    "pre_embedding_uni = np.load(train_root+'uni_col_w2v_100d_f.npy')\n",
    "pre_vocab_uni = json.load(open(train_root+'uni_col_vocab_100d_f.json','r'))\n",
    "pre_vocab_uni.update({'_PAD_':len(pre_vocab_uni)})\n",
    "pre_embedding_uni = np.concatenate((pre_embedding_uni,np.zeros((1,100)) ))\n",
    "print(len(pre_embedding_uni),len(pre_vocab_uni))\n",
    "\n",
    "vocab = {\n",
    "    'creative':pre_vocab_cre,\n",
    "    'uni_col':pre_vocab_uni,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 s, sys: 1.97 s, total: 33 s\n",
      "Wall time: 33 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>821396 877468 209778 1683713 122032 71691 1940...</td>\n",
       "      <td>7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2</td>\n",
       "      <td>20 20 20 39 40 43 46 52 60 64 64 73 76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63441 155822 39714 609050 13069 441462 1266180...</td>\n",
       "      <td>22885_87_318_2 10686_80_238_2 18562_129_6_2 25...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>661347 808612 593522 825434 710859 726940 3920...</td>\n",
       "      <td>32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39588 589886 574787 1892854 1230094 2264105 31...</td>\n",
       "      <td>19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>296145 350759 24333 43235 852327 1054434 12964...</td>\n",
       "      <td>11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999996</td>\n",
       "      <td>190253 309607 1099 567833 571808 33159 1560316...</td>\n",
       "      <td>14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999997</td>\n",
       "      <td>20588 351431 15563 395549 169325 530723 43044 ...</td>\n",
       "      <td>11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999998</td>\n",
       "      <td>642652 932655 670 6508 944753 3507884 3123952 ...</td>\n",
       "      <td>29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>16 22 66 80 83 84 85 88 89 89 90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999999</td>\n",
       "      <td>69204 602554 498385 69204 2293419 3007031 2996...</td>\n",
       "      <td>24952_26858_60_3 28581_35561_\\N_4 28874_26858_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>3000000</td>\n",
       "      <td>44891 48221 17705 51330 192726 192492 192492 1...</td>\n",
       "      <td>20794_145_60_2 20794_145_60_2 17960_145_60_2 1...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                        creative_id  \\\n",
       "0              1  821396 877468 209778 1683713 122032 71691 1940...   \n",
       "1              2  63441 155822 39714 609050 13069 441462 1266180...   \n",
       "2              3  661347 808612 593522 825434 710859 726940 3920...   \n",
       "3              4  39588 589886 574787 1892854 1230094 2264105 31...   \n",
       "4              5  296145 350759 24333 43235 852327 1054434 12964...   \n",
       "...          ...                                                ...   \n",
       "2999995  2999996  190253 309607 1099 567833 571808 33159 1560316...   \n",
       "2999996  2999997  20588 351431 15563 395549 169325 530723 43044 ...   \n",
       "2999997  2999998  642652 932655 670 6508 944753 3507884 3123952 ...   \n",
       "2999998  2999999  69204 602554 498385 69204 2293419 3007031 2996...   \n",
       "2999999  3000000  44891 48221 17705 51330 192726 192492 192492 1...   \n",
       "\n",
       "                                                   uni_col  \\\n",
       "0        7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...   \n",
       "1        22885_87_318_2 10686_80_238_2 18562_129_6_2 25...   \n",
       "2        32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...   \n",
       "3        19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...   \n",
       "4        11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...   \n",
       "...                                                    ...   \n",
       "2999995  14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...   \n",
       "2999996  11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...   \n",
       "2999997  29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...   \n",
       "2999998  24952_26858_60_3 28581_35561_\\N_4 28874_26858_...   \n",
       "2999999  20794_145_60_2 20794_145_60_2 17960_145_60_2 1...   \n",
       "\n",
       "                                               click_times  \\\n",
       "0                                1 1 1 1 1 1 1 1 1 1 1 1 2   \n",
       "1        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "4        1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                    ...   \n",
       "2999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2999996  1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...   \n",
       "2999997                              1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999998              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999999  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                      time  age  gender  \n",
       "0                   20 20 20 39 40 43 46 52 60 64 64 73 76    4       1  \n",
       "1        10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...   10       1  \n",
       "2        12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...    7       2  \n",
       "3        8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...    5       1  \n",
       "4        3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...    4       1  \n",
       "...                                                    ...  ...     ...  \n",
       "2999995  1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...    4       2  \n",
       "2999996  3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...    2       2  \n",
       "2999997                   16 22 66 80 83 84 85 88 89 89 90    4       2  \n",
       "2999998  7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...    3       2  \n",
       "2999999  1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...    8       2  \n",
       "\n",
       "[3000000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_root+'train_trf.csv',index_col = 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, uid, creative, uni_col,click_times, time, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            id: Unique id for the example.\n",
    "            text: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.id = uid\n",
    "        self.text = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 feature,\n",
    "                 label\n",
    "                 ):\n",
    "        self.example_id = example_id\n",
    "        creative, uni_col, click_times, time = feature\n",
    "        self.feature = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "def read_examples(df, is_training):\n",
    "    if not is_training:\n",
    "        df['label'] = np.zeros(len(df), dtype=np.int64)\n",
    "    examples = []\n",
    "    for idex, row in df.iterrows():\n",
    "        if is_training:\n",
    "            label = row['age']\n",
    "        else:\n",
    "            label = row['label']\n",
    "        examples.append(InputExample(uid=idex, creative=row['creative_id'], uni_col =row['uni_col'], \n",
    "                                     click_times=row['click_times'], time = row['time'], label=label-1))\n",
    "    return examples, df\n",
    "\n",
    "def convert_examples_to_features(examples, word_to_id, max_seq_length):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        #!!!!!!!!!!!!!!!!!!!##\n",
    "        content=['creative','uni_col']\n",
    "        feature=[]\n",
    "        for onekind in content:\n",
    "            tokens_text = example.text[onekind].split()\n",
    "            tokens=[]\n",
    "            for token_text in tokens_text:\n",
    "                if token_text in word_to_id[onekind]:\n",
    "                    tokens.append(token_text)\n",
    "                else:\n",
    "                    tokens.append('_PAD_')\n",
    "            if len(tokens)>=max_seq_length:\n",
    "                tokens = tokens[:max_seq_length]\n",
    "            else:\n",
    "                tokens += ['_PAD_']*(max_seq_length-len(tokens))\n",
    "            token_ids = [word_to_id[onekind][token] for token in tokens]\n",
    "            feature.append(token_ids)\n",
    "        ###for click_times\n",
    "        tokens_text = example.text['click_times'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "            if int(token_text)<=4:\n",
    "                tokens.append(int(token_text))\n",
    "            else:\n",
    "                tokens.append(1)\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "        ###for time\n",
    "        tokens_text = example.text['time'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "                tokens.append(int(token_text))\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "            \n",
    "        \n",
    "        label = example.label\n",
    "\n",
    "        if example_index < 1:\n",
    "            print(example.id,'/n',feature,'/n',label)\n",
    "#             logger.info(\"*** Example ***\")\n",
    "#             logger.info(\"idx: {}\".format(example_index))\n",
    "#             logger.info(\"id: {}\".format(example.id))\n",
    "#             logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
    "#             logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
    "#             logger.info(\"input_mask: {}\".format(len(input_mask)))\n",
    "#             logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n",
    "#             logger.info(\"label: {}\".format(label))\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id=example.id,\n",
    "                feature= feature,\n",
    "                label=label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_class=10,dim=400,num_head=4,hidden=1024,dropout=0.1,max_seq_length=64):\n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_cre = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_cre,dtype=torch.float32), freeze=True)\n",
    "        self.embedding_uni = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_uni,dtype=torch.float32), freeze=True)\n",
    "        self.embeddingLN = nn.LayerNorm(dim, elementwise_affine=True)\n",
    "\n",
    "        self.postion_embedding = Positional_Encoding(dim)\n",
    "        self.encoder = Encoder(dim,num_head,hidden,dropout)#config.dim_model, config.num_head, config.hidden, config.dropout\n",
    "        self.encoders = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder)\n",
    "            # Encoder(config.dim_model, config.num_head, config.hidden, config.dropout)\n",
    "            for _ in range(1)])#config.num_encoder\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=400, hidden_size=768, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=0.5 )\n",
    "#         self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "        # self.fc1 = nn.Linear(config.pad_size * config.dim_model, config.num_classes)\n",
    "        # self.fc2 = nn.Linear(config.last_hidden, config.num_classes)\n",
    "        # self.fc1 = nn.Linear(config.dim_model, config.num_classes)\n",
    "        self.maxpool = nn.MaxPool1d(max_seq_length)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, cre, uni, clk, time):\n",
    "        x_cre = self.embedding_cre(cre)\n",
    "        x_uni = self.embedding_uni(uni)\n",
    "        x = torch.cat((x_cre, x_uni), 2)\n",
    "        x = self.embeddingLN(x)\n",
    "\n",
    "        out_trf = self.postion_embedding(x, time)\n",
    "        mask = clk.unsqueeze(1).expand(clk.size(0), clk.size(1), clk.size(1))#batch*seq*seq\n",
    "        for encoder in self.encoders:\n",
    "            out_trf = encoder(out_trf, mask)\n",
    "\n",
    "        pad = torch.clamp(clk,0,1).unsqueeze(2)        \n",
    "        out, _ = self.lstm(out_trf*pad)\n",
    "#         out = self.fc(out[:,-1,:])\n",
    "        # out = out.view(out.size(0), -1)#batch *seq*dim\n",
    "        # # out = torch.mean(out, 1)\n",
    "        # out = self.fc1(out)\n",
    "#         out = torch.cat((out_trf, out), 2)\n",
    "        out = out+(1-pad)*(-10000)\n",
    "        out = F.tanh(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.maxpool(out).squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.attention(x, mask)\n",
    "        out = self.feed_forward(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dim = dim_model\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "        pe = torch.tensor([[pos / (10000.0 ** (i // 2 * 2.0 / self.dim)) for i in range(self.dim)] for pos in range(92)],dtype=torch.float32)\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2])\n",
    "        self.embedding_pos = nn.Embedding.from_pretrained(pe, freeze=True)\n",
    "    def forward(self, x, time):\n",
    "\n",
    "        x_pos = self.embedding_pos(time)\n",
    "        out = x + x_pos\n",
    "        out = self.layer_norm(out)\n",
    "#         out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    '''Scaled Dot-Product Attention '''\n",
    "    def __init__(self):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__()\n",
    "#         self.atten_dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, Q, K, V, scale=None, mask =None):\n",
    "\n",
    "        attention = torch.matmul(Q, K.transpose(-1, -2))# scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "        if 1:  # TODO change this\n",
    "            # attention = attention.masked_fill_(mask == 0, -1e9)\n",
    "            attention = attention*torch.log2(1+mask)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        ###L dropout\n",
    "#         attention = self.atten_dropout(attention)\n",
    "        context = torch.matmul(attention, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, dropout=0.1):\n",
    "        super(Multi_Head_Attention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        assert dim_model % num_head == 0\n",
    "        self.dim_head = dim_model // self.num_head\n",
    "        self.fc_Q = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_K = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_V = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.fc = nn.Linear(num_head * self.dim_head, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        batch_size = x.size(0)\n",
    "        Q = self.fc_Q(x)\n",
    "        K = self.fc_K(x)\n",
    "        V = self.fc_V(x)\n",
    "        Q = Q.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        K = K.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "\n",
    "        if 1:  # TODO\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_head, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]  # TODO change this\n",
    "        scale = K.size(-1) ** -0.5  # 缩放因子\n",
    "        context = self.attention(Q, K, V, scale, mask)\n",
    "        #context: [batch_size x len_q x n_heads * d_v]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_head * self.num_head)\n",
    "        out = self.fc(context)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Position_wise_Feed_Forward(nn.Module):\n",
    "    def __init__(self, dim_model, hidden, dropout=0.0):\n",
    "        super(Position_wise_Feed_Forward, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.gelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 98\n",
    "batch_size = 128\n",
    "# tokenizer = jieba.lcut\n",
    "\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 20\n",
    "patience = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "# device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothLabelCritierion(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    1. Add label smoothing\n",
    "    2. Calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_smoothing=0.0):\n",
    "        super(SmoothLabelCritierion, self).__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.LogSoftmax = nn.LogSoftmax()\n",
    "\n",
    "        # When label smoothing is turned on, KL-divergence is minimized\n",
    "        # If label smoothing value is set to zero, the loss\n",
    "        # is equivalent to NLLLoss or CrossEntropyLoss.\n",
    "        if label_smoothing > 0:\n",
    "            self.criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "        else:\n",
    "            self.criterion = nn.NLLLoss()\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "\n",
    "    def _smooth_label(self, num_tokens):\n",
    "\n",
    "        one_hot = torch.randn(1, num_tokens)\n",
    "        one_hot.fill_(self.label_smoothing / (num_tokens - 1))\n",
    "        return one_hot\n",
    "\n",
    "    def _bottle(self, v):\n",
    "        return v.view(-1, v.size(2))\n",
    "\n",
    "    def forward(self, dec_outs, labels):\n",
    "        # Map the output to (0, 1)\n",
    "        scores = self.LogSoftmax(dec_outs)\n",
    "        # n_class\n",
    "        num_tokens = scores.size(-1)\n",
    "\n",
    "        gtruth = labels.view(-1)\n",
    "        if self.confidence < 1:\n",
    "            tdata = gtruth.detach()\n",
    "            one_hot = self._smooth_label(num_tokens)\n",
    "            if labels.is_cuda:\n",
    "                one_hot = one_hot.cuda()\n",
    "            tmp_ = one_hot.repeat(gtruth.size(0), 1)\n",
    "            tmp_.scatter_(1, tdata.unsqueeze(1), self.confidence)\n",
    "            gtruth = tmp_.detach()\n",
    "        loss = self.criterion(scores, gtruth)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(train, test_size=0.01, random_state=49, shuffle=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1481/891000 [00:00<02:09, 6877.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524247 /n [[10883, 323847, 57681, 60553, 1793252, 99604, 970091, 21, 64456, 4671, 6838, 289772, 94346, 49503, 1109620, 234878, 9394, 3907, 14099, 21, 520, 131272, 87310, 4061, 80, 1793253, 262276, 3907, 165971, 46591, 1793254, 323265, 1098558, 8301, 2705, 78787, 20, 133, 99531, 27, 250784, 497152, 85898, 20, 927773, 145926, 214463, 4276, 2449772, 20, 80, 27, 229239, 900892, 8621, 12535, 1166758, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772], [523, 2188, 3360, 7177, 2519, 662, 40876, 43, 1228, 966, 1490, 1638, 339, 11327, 662, 1764, 523, 1294, 554, 43, 0, 6235, 1297, 1294, 11, 2862, 13408, 1294, 346, 1294, 3184, 352, 10604, 16, 3790, 2580, 50, 11, 4692, 50, 2188, 343, 2908, 50, 524, 343, 299, 16, 1272, 50, 11, 50, 343, 29381, 1343, 5104, 2867, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845], [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 9, 10, 10, 12, 15, 16, 18, 18, 18, 19, 19, 21, 21, 24, 27, 30, 32, 32, 34, 34, 34, 36, 38, 40, 44, 46, 48, 50, 52, 53, 53, 54, 54, 55, 56, 58, 60, 62, 64, 66, 68, 70, 71, 72, 76, 78, 78, 80, 80, 82, 84, 86, 86, 88, 89, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 891000/891000 [01:56<00:00, 7632.46it/s]\n",
      " 20%|█▉        | 1789/9000 [00:00<00:00, 8904.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222270 /n [[6, 7975, 82050, 19156, 28038, 17124, 1, 1651566, 26, 7628, 364318, 1, 251166, 26, 709, 408491, 9, 47214, 458369, 9, 74091, 20367, 6036, 1, 974, 1229, 1391, 36456, 42033, 15966, 5622, 25, 447, 284, 214507, 144974, 123107, 20482, 747908, 24055, 18553, 677147, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772], [28, 1862, 1980, 10005, 548, 2729, 3, 31302, 43, 541, 6642, 3, 979, 43, 414, 452, 3, 4473, 3140, 3, 1890, 1109, 4671, 3, 811, 29, 32, 1316, 137, 348, 32, 8, 253, 388, 1515, 222, 2664, 4098, 11759, 2664, 476, 227, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3, 4, 4, 4, 8, 10, 13, 14, 16, 16, 17, 18, 24, 25, 25, 25, 26, 28, 33, 35, 46, 47, 48, 49, 50, 52, 55, 56, 60, 64, 65, 67, 68, 70, 72, 76, 78, 86, 86, 86, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:01<00:00, 8941.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 56s, sys: 6.52 s, total: 5min 3s\n",
      "Wall time: 5min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "valid_examples, valid_df = read_examples(valid, is_training=True)\n",
    "valid_features = convert_examples_to_features(valid_examples, vocab, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 891000/891000 [00:00<00:00, 1401101.67it/s]\n",
      "100%|██████████| 891000/891000 [00:00<00:00, 1263286.50it/s]\n",
      "100%|██████████| 891000/891000 [00:00<00:00, 1430195.39it/s]\n",
      "100%|██████████| 891000/891000 [00:00<00:00, 1245067.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "valid_input_cre = torch.tensor(np.array([valid_feature.feature['creative'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_uni = torch.tensor(np.array([valid_feature.feature['uni_col'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_clk= torch.tensor(np.array([valid_feature.feature['click_times'] for valid_feature in valid_features]), dtype=torch.float32)\n",
    "valid_input_tim= torch.tensor(np.array([valid_feature.feature['time'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "valid_label = torch.tensor(np.array([valid_feature.label for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_input_cre,train_input_uni,train_input_clk,train_input_tim, train_label)\n",
    "valid_data = torch.utils.data.TensorDataset(valid_input_cre,valid_input_uni,valid_input_clk,valid_input_tim, valid_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(4)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler_warm= torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step:step/(2*len(train_loader)))\n",
    "\n",
    "best_acc = 0.\n",
    "valid_best = np.zeros((valid_label.size(0), 10))\n",
    "\n",
    "early_stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1759/3000000 [00:00<05:49, 8584.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[369522, 82667, 30791, 54327, 1122, 57, 17354, 2501, 3140, 1903, 18115, 1903, 150654, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [681, 3524, 2153, 2038, 1190, 42, 288, 2059, 880, 886, 847, 886, 17, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [20, 20, 20, 39, 40, 43, 46, 52, 60, 64, 64, 73, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000000/3000000 [06:19<00:00, 7898.67it/s] \n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1232859.29it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1338850.50it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1348191.00it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1337804.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###five fold\n",
    "####\n",
    "\n",
    "# train = pd.read_csv(train_root+'train_creative.csv',index_col = 0)\n",
    "\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "\n",
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "import gc\n",
    "del train\n",
    "del train_df\n",
    "del train_examples\n",
    "del train_features\n",
    "\n",
    "# del test_group\n",
    "# del test_df \n",
    "# del test_examples\n",
    "# del test_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================     fold 1        ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 17579/17579 [59:04<00:00,  4.96it/s] \n",
      "5860it [06:15, 15.59it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.08749237, valid loss: 1.17504477, acc: 0.51023200, f1: 0.50809725, best_f1: 1.17504477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17579/17579 [59:10<00:00,  4.95it/s] \n",
      "5860it [06:15, 15.60it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 1.08292990, valid loss: 1.17529610, acc: 0.51048267, f1: 0.50826154, best_f1: 1.17504477\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17579/17579 [59:11<00:00,  4.95it/s] \n",
      "5860it [06:15, 15.62it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 1.08023783, valid loss: 1.17539755, acc: 0.51063467, f1: 0.50829112, best_f1: 1.17504477\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 12685/17579 [42:42<16:24,  4.97it/s] "
     ]
    }
   ],
   "source": [
    "###five fold\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=107)\n",
    "# off: out-of-fold\n",
    "# oof_test = np.zeros((100_0000, 10), dtype=np.float32)\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(train_label, train_label)):\n",
    "    if fold!=1:\n",
    "        continue\n",
    "\n",
    "    print('================     fold {}        ==============='.format(fold))\n",
    "    train_input_fold_cre = torch.tensor(train_input_cre[train_index], dtype=torch.long)\n",
    "    train_input_fold_uni = torch.tensor(train_input_uni[train_index], dtype=torch.long)\n",
    "    train_input_fold_clk = torch.tensor(train_input_clk[train_index], dtype=torch.float32)\n",
    "    train_input_fold_tim = torch.tensor(train_input_tim[train_index], dtype=torch.long)\n",
    "    train_label_fold = torch.tensor(train_label[train_index], dtype=torch.long)\n",
    "    \n",
    "    valid_input_fold_cre = torch.tensor(train_input_cre[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_uni = torch.tensor(train_input_uni[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_clk = torch.tensor(train_input_clk[valid_index], dtype=torch.float32)\n",
    "    valid_input_fold_tim = torch.tensor(train_input_tim[valid_index], dtype=torch.long)\n",
    "    valid_label_fold = torch.tensor(train_label[valid_index], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    train_data_fold  = torch.utils.data.TensorDataset(train_input_fold_cre,train_input_fold_uni,train_input_fold_clk,train_input_fold_tim, train_label_fold )\n",
    "    valid_data_fold  = torch.utils.data.TensorDataset(valid_input_fold_cre,valid_input_fold_uni,valid_input_fold_clk,valid_input_fold_tim,valid_label_fold )\n",
    "\n",
    "    train_loader_fold  = torch.utils.data.DataLoader(train_data_fold , batch_size=batch_size, shuffle=True)\n",
    "    valid_loader_fold  = torch.utils.data.DataLoader(valid_data_fold , batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "     \n",
    "        \n",
    "    torch.cuda.set_device(3)\n",
    "    model =  myModel(768,10,max_seq_length=max_seq_length)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age1.bin'))####TODO\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     loss_fn = SmoothLabelCritierion(label_smoothing=0.1)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.035},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    for param_group in optimizer.param_groups:####TODO\n",
    "        param_group['lr']=1e-6\n",
    "\n",
    "    best_val = 10000.\n",
    "    valid_best = np.zeros((valid_label_fold.size(0), 10))\n",
    "\n",
    "    early_stop = 0    \n",
    "    model.train()\n",
    "    \n",
    "    del train_input_cre\n",
    "    del train_input_uni\n",
    "    del train_input_clk\n",
    "    del train_input_tim\n",
    "    del pre_embedding_cre\n",
    "    del pre_embedding_uni\n",
    "    gc.collect()\n",
    "    for epoch in range(num_epochs):\n",
    "#         if epoch==16:\n",
    "#             model.load_state_dict(torch.load(train_root+'lstm_age1.bin'))\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr']=1e-6\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        for i, batch in enumerate(tqdm(train_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(y_pred, y_truth)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() / len(train_loader_fold)\n",
    "    # target.view(target.size(0), 1).long()\n",
    "        model.eval()\n",
    "        val_loss = 0.\n",
    "        valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "                y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "                val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "        if best_val >= val_loss:\n",
    "            early_stop = 0\n",
    "            best_val = val_loss\n",
    "            valid_best = valid_preds_fold\n",
    "            # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "            # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "            torch.save(model.state_dict(), train_root+'lstm_age1.bin')\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        print(\n",
    "            'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (epoch, train_loss, val_loss, acc, f1, best_val))\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if early_stop >= patience:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                if param_group['lr']>=3e-5:\n",
    "                    param_group['lr'] *= 0.3\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(param_group['lr'])\n",
    "\n",
    "            \n",
    "    test_preds_fold = np.zeros((100_0000, 10))\n",
    "    valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age1.bin'))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate( tqdm(test_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "    acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "    print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "                (acc, f1, best_val))\n",
    "   \n",
    "    \n",
    "    #oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "    oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "4688it [07:57,  9.83it/s]\n",
      "100%|██████████| 7813/7813 [13:09<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: best, acc: 0.51140000, f1: 0.50849440, best_f1: 0.91045324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "test_preds_fold = np.zeros((100_0000, 10))\n",
    "valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age1.bin', map_location={'cuda:3':'cuda:0'}))\n",
    "model.eval()\n",
    "# # model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "        valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (acc, f1, best_val))\n",
    "\n",
    "\n",
    "#oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "# oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "0.511615\n",
      "0.5116433333333333\n",
      "0.511685\n",
      "0.5117183333333334\n",
      "0.51176\n",
      "0.5117783333333333\n",
      "0.511825\n",
      "0.5118883333333333\n",
      "0.5119\n",
      "0.5119116666666667\n",
      "0.5119733333333333\n",
      "0.5120183333333334\n",
      "0.5120316666666667\n",
      "0.512045\n",
      "0.51206\n",
      "0.512075\n",
      "0.512085\n",
      "0.51209\n",
      "0.5120916666666666\n",
      "0.5121\n",
      "round:  2\n",
      "0.512105\n",
      "0.5121066666666667\n",
      "0.5121333333333333\n",
      "0.5121483333333333\n",
      "0.512165\n",
      "round:  3\n",
      "0.5121766666666666\n",
      "0.5121833333333333\n",
      "0.5121983333333333\n",
      "0.5122066666666667\n",
      "round:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8, 0.99, 1.02, 1.02, 0.97, 1.0, 0.93, 0.97, 1.0, 1.12]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num=10\n",
    "weights = [1.0]*class_num\n",
    "\n",
    "def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "    weight = init_weight.copy()\n",
    "    f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(\n",
    "        axis=1))\n",
    "    flag_score = 0\n",
    "    round_num = 1\n",
    "    while(flag_score != f_best):\n",
    "        print(\"round: \", round_num)\n",
    "        round_num += 1\n",
    "        flag_score = f_best\n",
    "        for c in range(class_num):\n",
    "            for n_w in range(0, 2000,10):\n",
    "                num = n_w * step\n",
    "                new_weight = weight.copy()\n",
    "                new_weight[c] = num\n",
    "\n",
    "                prob_df = raw_prob.copy()\n",
    "                prob_df = prob_df * np.array(new_weight)\n",
    "\n",
    "                f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(\n",
    "                    axis=1))\n",
    "                if f > f_best:\n",
    "                    weight = new_weight.copy()\n",
    "                    f_best = f\n",
    "                    print(f)\n",
    "    return weight\n",
    "search_weight(valid_label_fold,valid_preds_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test = np.argmax(oof_test, axis=1)+1\n",
    "oof_test\n",
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = oof_test\n",
    "submission\n",
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_preds_fold).to_csv('five51.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48612777777777777"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6961 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "  0%|          | 1/6961 [00:00<1:04:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[-3.9947e-02, -6.1290e-02, -2.1701e-02,  ..., -7.0041e-03,\n",
      "           2.6523e-02, -1.7402e-02],\n",
      "         [-3.4824e-03, -7.1104e-02, -4.5632e-02,  ..., -5.5817e-02,\n",
      "           5.6632e-02,  1.5225e-02],\n",
      "         [-3.0360e-03, -4.5969e-02, -5.1987e-02,  ..., -8.6170e-02,\n",
      "          -2.7436e-02, -7.9209e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.4808e-02, -4.8341e-02,  1.7451e-02,  ..., -1.6842e-01,\n",
      "           6.5663e-02,  6.1598e-03],\n",
      "         [ 6.5141e-02, -6.8690e-02,  2.7849e-02,  ..., -1.7597e-01,\n",
      "           1.8323e-02, -6.4803e-02],\n",
      "         [-9.6473e-03, -6.5777e-02,  4.0464e-02,  ..., -1.1920e-01,\n",
      "           2.4846e-03, -6.3421e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 5.4255e-03, -3.1570e-02,  3.1621e-03,  ..., -1.6057e-01,\n",
      "           1.7592e-02, -5.9900e-02],\n",
      "         [-2.9773e-02, -3.0562e-02, -2.6061e-02,  ..., -1.8056e-01,\n",
      "           2.1004e-02, -1.1054e-02],\n",
      "         [-4.4591e-02, -6.1004e-03, -5.7782e-02,  ..., -1.8081e-01,\n",
      "           4.3891e-02,  6.8424e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.7287e-02, -7.5113e-03, -2.9996e-03,  ..., -1.1697e-01,\n",
      "           1.1234e-01, -8.6865e-02],\n",
      "         [ 4.1834e-02, -4.5040e-02,  8.5145e-04,  ..., -1.2284e-01,\n",
      "           1.5010e-01, -1.0820e-01],\n",
      "         [ 2.4712e-02, -6.6722e-02,  1.6932e-02,  ..., -1.4587e-01,\n",
      "           1.3190e-01, -1.1565e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.6358e-02, -2.5583e-02,  7.6976e-02,  ..., -1.6399e-01,\n",
      "          -9.3746e-02, -7.1812e-04],\n",
      "         [ 4.0114e-02, -5.7998e-02,  8.8651e-02,  ..., -1.5392e-01,\n",
      "          -6.2743e-02, -4.2545e-02],\n",
      "         [ 9.6435e-03, -4.5575e-02,  5.5779e-02,  ..., -1.6230e-01,\n",
      "          -8.1051e-02, -6.9137e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 1.1394e-02, -2.1927e-02,  4.4840e-02,  ..., -1.2087e-01,\n",
      "           7.9007e-02,  1.7206e-02],\n",
      "         [ 3.5513e-02, -6.8515e-02,  4.8898e-02,  ..., -1.1980e-01,\n",
      "           8.7012e-02, -6.3579e-02],\n",
      "         [ 3.9599e-02, -6.9358e-02,  6.7597e-02,  ..., -4.6688e-02,\n",
      "           4.0167e-02, -9.8011e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/6961 [00:00<52:42,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[-2.4654e-02, -4.5801e-02,  5.4477e-02,  ..., -2.3522e-01,\n",
      "          -4.3820e-02,  8.7354e-02],\n",
      "         [ 2.2563e-02, -6.6790e-02,  1.0983e-02,  ..., -2.8211e-01,\n",
      "          -8.6918e-02,  8.4768e-02],\n",
      "         [-1.2232e-02, -1.2180e-01,  6.5191e-02,  ..., -3.0432e-01,\n",
      "          -7.7432e-02,  5.4325e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 1.5262e-02, -5.8856e-02,  2.5012e-02,  ..., -2.1768e-01,\n",
      "          -2.7425e-02,  8.1236e-02],\n",
      "         [ 5.3372e-03, -6.3511e-02,  8.6186e-03,  ..., -2.2034e-01,\n",
      "          -3.7714e-02,  7.5724e-02],\n",
      "         [ 1.9226e-02, -9.5181e-02, -2.4799e-02,  ..., -2.9324e-01,\n",
      "          -5.6031e-02, -1.9639e-04],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-8.7902e-04, -6.1208e-02,  1.2766e-02,  ..., -2.0811e-01,\n",
      "           2.3202e-02,  5.2521e-02],\n",
      "         [-6.0705e-03, -1.4499e-01,  8.1240e-02,  ..., -2.6576e-01,\n",
      "          -8.0454e-02,  1.1512e-02],\n",
      "         [-9.4660e-03, -1.4378e-01,  5.0860e-02,  ..., -3.1108e-01,\n",
      "           6.1425e-03,  5.3388e-03],\n",
      "         ...,\n",
      "         [ 2.6553e-02, -1.5419e-01,  1.3612e-01,  ..., -2.5433e-01,\n",
      "          -9.1587e-02,  5.5426e-02],\n",
      "         [-1.3136e-02, -1.9854e-01,  6.0717e-02,  ..., -2.5383e-01,\n",
      "          -8.2408e-02,  5.7237e-02],\n",
      "         [-3.3892e-02, -1.4810e-01,  6.9508e-02,  ..., -1.4906e-01,\n",
      "          -7.7186e-02,  3.2528e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.2528e-03,  2.1568e-02,  4.3604e-03,  ..., -1.7224e-01,\n",
      "          -7.0001e-02,  1.2913e-02],\n",
      "         [-2.1051e-02, -9.0518e-03,  6.7650e-02,  ..., -1.9175e-01,\n",
      "          -2.7661e-02, -3.8774e-03],\n",
      "         [ 6.0140e-02, -6.0773e-02,  5.0162e-02,  ..., -1.8590e-01,\n",
      "          -2.9558e-02, -1.4595e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.6157e-02, -6.9205e-02,  7.0807e-02,  ..., -1.5836e-01,\n",
      "           6.7306e-02,  8.4635e-02],\n",
      "         [ 9.0676e-02, -1.2102e-01,  6.0752e-02,  ..., -2.0204e-01,\n",
      "           5.7425e-03,  6.0173e-02],\n",
      "         [ 1.1181e-01, -1.4068e-01,  4.3259e-02,  ..., -2.1939e-01,\n",
      "           2.4479e-02,  2.9476e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 1.2505e-02, -3.6730e-02, -2.1170e-02,  ..., -1.8679e-01,\n",
      "          -1.6544e-02, -6.1338e-03],\n",
      "         [-3.6555e-03, -1.2985e-01, -9.7228e-03,  ..., -1.9637e-01,\n",
      "          -3.2811e-02, -2.8636e-02],\n",
      "         [-1.7945e-02, -1.5111e-01,  6.6433e-02,  ..., -2.5787e-01,\n",
      "          -2.3161e-02, -1.6617e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/6961 [00:01<45:35,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 4.3667e-02, -4.2698e-02,  8.0023e-02,  ..., -3.0724e-01,\n",
      "          -2.5556e-02, -9.6268e-03],\n",
      "         [ 1.1498e-01, -1.1423e-01,  8.2973e-02,  ..., -3.5805e-01,\n",
      "           1.0201e-02,  1.0736e-04],\n",
      "         [ 9.9261e-02, -1.7018e-01,  5.8134e-02,  ..., -3.6081e-01,\n",
      "           2.0576e-02, -5.0144e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.0299e-02, -7.1380e-02,  1.1850e-02,  ..., -4.3856e-01,\n",
      "          -1.2045e-01,  5.9369e-02],\n",
      "         [ 4.0878e-02, -1.5580e-01,  5.2361e-02,  ..., -4.4155e-01,\n",
      "          -9.5965e-02,  4.5577e-02],\n",
      "         [ 5.7919e-02, -1.9102e-01, -3.9300e-03,  ..., -4.6345e-01,\n",
      "          -9.9933e-02,  3.1727e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 8.3527e-03, -7.7858e-02,  2.6524e-02,  ..., -4.0142e-01,\n",
      "          -1.1518e-01, -2.7297e-02],\n",
      "         [ 4.8654e-02, -1.2618e-01,  8.4993e-02,  ..., -4.0547e-01,\n",
      "          -1.4330e-01, -2.9238e-02],\n",
      "         [ 4.3283e-02, -1.5621e-01, -3.2906e-02,  ..., -3.6291e-01,\n",
      "          -1.1782e-01,  4.5671e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.9898e-02, -4.8045e-02,  3.0285e-02,  ..., -3.6677e-01,\n",
      "          -6.5902e-02,  3.8210e-02],\n",
      "         [-7.9341e-02, -1.1704e-01,  3.3699e-02,  ..., -4.5248e-01,\n",
      "          -7.3674e-02,  1.2424e-02],\n",
      "         [-6.7539e-02, -1.5715e-01, -5.0588e-02,  ..., -4.2467e-01,\n",
      "          -7.9706e-02,  1.7487e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 7.6647e-02, -1.1556e-01, -8.1911e-03,  ..., -4.3481e-01,\n",
      "          -1.2575e-01,  1.4634e-02],\n",
      "         [ 8.9370e-02, -1.9857e-01, -2.5147e-03,  ..., -4.0696e-01,\n",
      "          -1.9922e-01,  3.5597e-02],\n",
      "         [ 9.4450e-02, -1.9684e-01, -4.0516e-03,  ..., -3.8430e-01,\n",
      "          -8.3209e-02,  6.6707e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.0305e-02, -6.8482e-02, -4.3245e-02,  ..., -3.6376e-01,\n",
      "          -2.3303e-02,  3.6667e-03],\n",
      "         [ 5.5910e-02, -1.7142e-01, -3.1709e-02,  ..., -4.2034e-01,\n",
      "          -1.0266e-02,  1.3003e-02],\n",
      "         [-2.3256e-02, -1.9671e-01,  5.7493e-03,  ..., -4.5176e-01,\n",
      "          -7.2254e-02,  3.8464e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/6961 [00:01<39:49,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]]], device='cuda:4') tensor([[[ 7.7411e-02, -6.3906e-02,  2.1219e-02,  ..., -4.4216e-01,\n",
      "          -2.0091e-01,  1.8321e-01],\n",
      "         [ 1.2877e-01, -1.5951e-01,  1.5729e-02,  ..., -5.0451e-01,\n",
      "          -2.7872e-01,  1.0259e-01],\n",
      "         [ 7.3646e-02, -1.8501e-01, -7.9460e-03,  ..., -4.5259e-01,\n",
      "          -2.0874e-01,  1.1256e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 8.4000e-02, -1.1502e-01,  3.0167e-02,  ..., -4.0735e-01,\n",
      "          -2.1795e-01,  2.1728e-01],\n",
      "         [ 1.9522e-01, -2.4060e-01,  2.0079e-02,  ..., -3.2868e-01,\n",
      "          -9.6074e-02,  1.9743e-01],\n",
      "         [ 2.5639e-01, -2.4136e-01, -2.1434e-02,  ..., -3.7249e-01,\n",
      "          -1.7158e-01,  1.7143e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 7.5315e-02, -1.7663e-02,  2.6084e-02,  ..., -3.6306e-01,\n",
      "          -1.7052e-01,  1.3791e-01],\n",
      "         [ 1.1081e-01, -7.1429e-02, -3.4961e-02,  ..., -4.2956e-01,\n",
      "          -2.2825e-01,  1.4674e-01],\n",
      "         [ 1.3110e-01, -1.0112e-01, -9.0165e-02,  ..., -4.2613e-01,\n",
      "          -1.9192e-01,  9.9857e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.4647e-02, -1.3568e-01,  3.4903e-02,  ..., -3.7305e-01,\n",
      "          -1.4373e-01,  9.4038e-02],\n",
      "         [-2.4678e-03, -1.8601e-01, -1.1686e-02,  ..., -3.9176e-01,\n",
      "          -1.1264e-01,  3.6269e-02],\n",
      "         [ 1.4755e-01, -1.8221e-01,  1.3980e-02,  ..., -3.9249e-01,\n",
      "          -1.0600e-01,  9.3568e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 9.0536e-02, -6.1619e-02, -3.6104e-02,  ..., -2.9250e-01,\n",
      "          -1.6081e-01,  1.3212e-01],\n",
      "         [ 1.2529e-01, -1.4703e-01, -9.1973e-02,  ..., -3.5923e-01,\n",
      "          -1.9019e-01,  1.3197e-01],\n",
      "         [ 1.1437e-01, -1.9184e-01, -9.7508e-02,  ..., -3.4279e-01,\n",
      "          -1.6782e-01,  1.3679e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 4.7970e-02, -3.3147e-02, -2.2150e-02,  ..., -3.2944e-01,\n",
      "          -1.2784e-01,  1.7828e-01],\n",
      "         [ 1.4544e-01, -5.2734e-02, -2.2527e-02,  ..., -3.4223e-01,\n",
      "          -1.4795e-01,  1.9783e-01],\n",
      "         [ 2.0962e-01, -1.3931e-01, -1.1121e-01,  ..., -3.6604e-01,\n",
      "          -1.3312e-01,  1.7166e-01],\n",
      "         ...,\n",
      "         [ 2.6697e-01, -1.5557e-01,  3.2946e-03,  ..., -3.2457e-01,\n",
      "          -1.2678e-01,  3.7826e-02],\n",
      "         [ 2.7400e-01, -1.7800e-01, -5.1764e-03,  ..., -2.3277e-01,\n",
      "          -1.2921e-01, -4.7622e-02],\n",
      "         [ 2.7068e-01, -1.1498e-01,  4.5547e-03,  ..., -2.2358e-01,\n",
      "          -7.4638e-02,  1.7066e-03]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/6961 [00:01<35:48,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 4.0444e-02, -7.5296e-02,  5.9126e-03,  ..., -3.7214e-01,\n",
      "          -8.1482e-02,  1.7011e-01],\n",
      "         [ 8.9425e-02, -1.3970e-01,  1.6926e-02,  ..., -4.6702e-01,\n",
      "          -1.2823e-01,  1.5544e-01],\n",
      "         [ 1.4534e-01, -1.7653e-01,  1.2074e-02,  ..., -4.1182e-01,\n",
      "          -2.1836e-01,  2.0250e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 4.7109e-02, -1.1429e-01, -9.7696e-03,  ..., -3.4701e-01,\n",
      "          -1.2100e-01,  1.9832e-01],\n",
      "         [ 9.4395e-02, -1.4443e-01,  3.4194e-04,  ..., -3.4533e-01,\n",
      "          -1.4963e-01,  2.0729e-01],\n",
      "         [ 7.9197e-02, -1.9381e-01, -1.2649e-01,  ..., -4.5520e-01,\n",
      "          -1.4295e-01,  2.1728e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 7.1346e-02, -9.9944e-02, -6.3239e-02,  ..., -3.0889e-01,\n",
      "          -9.5821e-02,  2.4641e-01],\n",
      "         [ 1.2224e-01, -1.2996e-01, -1.1321e-01,  ..., -3.4322e-01,\n",
      "          -1.4745e-01,  2.2562e-01],\n",
      "         [ 1.8954e-01, -1.7670e-01, -6.3201e-02,  ..., -3.8786e-01,\n",
      "          -1.0819e-01,  2.0425e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9563e-02, -7.2308e-02, -4.5843e-02,  ..., -3.0496e-01,\n",
      "          -1.4275e-01,  1.8638e-01],\n",
      "         [ 1.1033e-01, -1.6286e-01,  1.2394e-03,  ..., -3.6481e-01,\n",
      "          -1.2599e-01,  1.9538e-01],\n",
      "         [ 2.3294e-01, -1.5240e-01, -2.1935e-03,  ..., -4.5544e-01,\n",
      "          -1.6269e-01,  3.2585e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 5.4291e-02, -7.0516e-02, -4.6275e-02,  ..., -3.6495e-01,\n",
      "          -1.2373e-01,  1.1051e-01],\n",
      "         [ 9.6929e-02, -1.2258e-01, -2.4164e-02,  ..., -4.3056e-01,\n",
      "          -1.0534e-01,  7.4740e-02],\n",
      "         [ 1.9193e-01, -1.6633e-01, -4.9005e-02,  ..., -4.7181e-01,\n",
      "          -1.3960e-01,  1.7119e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 7.7605e-02, -6.7512e-02, -2.2197e-02,  ..., -3.1765e-01,\n",
      "          -1.4197e-01,  1.4994e-01],\n",
      "         [ 1.6122e-01, -1.5499e-01, -1.8091e-02,  ..., -3.7315e-01,\n",
      "          -1.8325e-01,  1.5845e-01],\n",
      "         [ 2.2494e-01, -1.9294e-01, -7.6828e-02,  ..., -3.9786e-01,\n",
      "          -1.7580e-01,  1.7130e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/6961 [00:01<33:01,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[-1.2089e-02, -8.3517e-02, -1.9139e-02,  ..., -3.8077e-01,\n",
      "          -1.2346e-01,  1.9811e-01],\n",
      "         [ 5.9103e-02, -1.5201e-01, -8.8928e-02,  ..., -3.7201e-01,\n",
      "          -1.3604e-01,  1.8781e-01],\n",
      "         [ 1.1742e-01, -2.7343e-01, -9.3581e-02,  ..., -4.1106e-01,\n",
      "          -1.0203e-01,  1.3464e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 8.4945e-02, -1.0266e-01, -5.3625e-02,  ..., -4.3225e-01,\n",
      "          -1.7000e-01,  1.6994e-01],\n",
      "         [ 1.5593e-01, -1.5482e-01, -8.5823e-02,  ..., -4.4520e-01,\n",
      "          -1.3615e-01,  1.5789e-01],\n",
      "         [ 2.4193e-01, -1.9653e-01, -7.7210e-02,  ..., -3.9501e-01,\n",
      "          -1.8606e-01,  1.4166e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.9264e-02, -1.1184e-01, -2.4123e-02,  ..., -4.0685e-01,\n",
      "          -4.3806e-02,  1.5125e-01],\n",
      "         [-8.2366e-03, -2.1317e-01, -9.9298e-02,  ..., -4.1885e-01,\n",
      "          -1.1227e-01,  1.7132e-01],\n",
      "         [ 1.1802e-01, -2.1411e-01, -6.1618e-02,  ..., -3.9209e-01,\n",
      "          -1.0051e-01,  1.6609e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7121e-02, -8.5965e-02, -4.5617e-02,  ..., -3.6756e-01,\n",
      "          -8.1530e-02,  1.8819e-01],\n",
      "         [ 3.8019e-02, -1.5833e-01, -7.3871e-02,  ..., -4.0559e-01,\n",
      "          -8.6080e-02,  1.2863e-01],\n",
      "         [ 1.2669e-01, -1.3517e-01, -1.2482e-01,  ..., -4.5063e-01,\n",
      "          -7.2089e-02,  1.1928e-01],\n",
      "         ...,\n",
      "         [ 1.2075e-01, -2.5762e-01, -5.9572e-02,  ..., -3.9215e-01,\n",
      "          -1.2894e-01,  9.8298e-02],\n",
      "         [ 1.3916e-01, -2.2543e-01, -8.7536e-02,  ..., -3.0235e-01,\n",
      "          -8.5824e-02,  8.9437e-02],\n",
      "         [ 1.2352e-01, -1.8903e-01, -6.5306e-02,  ..., -1.5505e-01,\n",
      "          -9.5898e-02,  3.0040e-02]],\n",
      "\n",
      "        [[ 3.3881e-02, -3.7684e-02, -2.8506e-02,  ..., -3.3297e-01,\n",
      "          -1.0265e-01,  1.6966e-01],\n",
      "         [ 5.5793e-02, -1.0445e-01, -2.0456e-03,  ..., -4.1463e-01,\n",
      "          -1.3161e-01,  1.9481e-01],\n",
      "         [ 6.8776e-02, -1.6365e-01, -5.6697e-02,  ..., -4.7702e-01,\n",
      "          -1.4235e-01,  1.5284e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 4.8784e-02, -1.0373e-01, -4.1512e-02,  ..., -2.3375e-01,\n",
      "          -8.5144e-02,  4.8548e-02],\n",
      "         [ 9.2819e-02, -1.9364e-01, -7.9120e-02,  ..., -2.6778e-01,\n",
      "          -8.2828e-02,  7.0116e-02],\n",
      "         [ 1.8445e-01, -1.8992e-01, -2.5867e-02,  ..., -2.6534e-01,\n",
      "          -6.5725e-02,  9.7959e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/6961 [00:01<31:08,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 4.4227e-02, -4.3736e-02, -5.1163e-02,  ..., -3.5727e-01,\n",
      "          -2.3518e-02,  6.0723e-02],\n",
      "         [ 1.0086e-01, -1.3059e-01, -1.2589e-02,  ..., -4.1991e-01,\n",
      "          -3.8548e-02,  1.0135e-01],\n",
      "         [ 1.0709e-01, -2.4167e-01, -8.9153e-02,  ..., -3.9850e-01,\n",
      "          -8.7083e-02,  9.1301e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-2.6276e-02, -2.9345e-02, -5.1796e-02,  ..., -2.6863e-01,\n",
      "          -9.2310e-02,  1.3164e-01],\n",
      "         [ 4.1709e-02, -7.7298e-02, -4.3485e-02,  ..., -3.5630e-01,\n",
      "          -1.0553e-01,  1.5864e-01],\n",
      "         [ 4.9702e-02, -1.1060e-01, -4.9531e-02,  ..., -3.3166e-01,\n",
      "          -9.6125e-02,  1.8135e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.1317e-02, -8.7284e-02, -9.9409e-04,  ..., -3.1760e-01,\n",
      "          -7.9380e-02,  1.7667e-01],\n",
      "         [ 4.3322e-02, -1.1198e-01, -8.4833e-02,  ..., -3.4500e-01,\n",
      "          -7.8037e-02,  1.4412e-01],\n",
      "         [ 7.6450e-02, -1.5722e-01, -9.7589e-02,  ..., -4.7350e-01,\n",
      "          -8.3571e-02,  2.2991e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.4277e-02, -4.1728e-02, -2.9389e-02,  ..., -3.5101e-01,\n",
      "          -5.0103e-02,  1.8622e-01],\n",
      "         [ 9.4868e-02, -9.7816e-02, -8.9647e-02,  ..., -4.0184e-01,\n",
      "          -7.5124e-02,  1.7849e-01],\n",
      "         [ 2.1849e-02, -1.4228e-01, -8.3132e-02,  ..., -4.3767e-01,\n",
      "          -8.2398e-02,  1.9327e-01],\n",
      "         ...,\n",
      "         [ 7.2468e-02, -1.7326e-01, -1.2852e-01,  ..., -3.1755e-01,\n",
      "          -9.5941e-02,  1.2607e-01],\n",
      "         [ 5.3671e-02, -1.4513e-01, -8.4226e-02,  ..., -2.6887e-01,\n",
      "          -7.1354e-02,  9.1343e-02],\n",
      "         [-2.2272e-03, -2.0374e-01, -3.1286e-02,  ..., -1.3858e-01,\n",
      "          -5.1108e-02,  8.4246e-02]],\n",
      "\n",
      "        [[ 1.0084e-01, -1.1352e-01, -4.9145e-02,  ..., -3.6181e-01,\n",
      "          -4.1417e-02,  8.8404e-02],\n",
      "         [ 1.3614e-01, -1.2436e-01, -8.6482e-02,  ..., -3.8603e-01,\n",
      "          -7.7561e-02,  1.0445e-01],\n",
      "         [ 1.7546e-01, -1.6956e-01, -8.9175e-02,  ..., -4.2473e-01,\n",
      "          -8.1664e-02,  1.4770e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 6.0611e-02, -1.1308e-01, -2.8346e-02,  ..., -3.9513e-01,\n",
      "          -4.3399e-02,  9.8517e-02],\n",
      "         [ 2.5244e-02, -1.6638e-01, -1.0043e-01,  ..., -4.4461e-01,\n",
      "          -6.2721e-02,  1.2759e-01],\n",
      "         [ 5.0486e-02, -2.2678e-01, -1.0525e-01,  ..., -3.8147e-01,\n",
      "          -6.4618e-02,  1.6199e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/6961 [00:02<29:56,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[-1.4800e-02, -3.1597e-02, -1.9490e-02,  ..., -3.1684e-01,\n",
      "          -6.2367e-02,  5.2485e-02],\n",
      "         [ 1.6576e-02, -8.5934e-02, -7.0816e-02,  ..., -2.8865e-01,\n",
      "          -7.2684e-02,  3.3964e-02],\n",
      "         [ 2.8594e-02, -9.6390e-02, -6.4206e-02,  ..., -2.7367e-01,\n",
      "          -9.2180e-02,  3.9037e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 5.0665e-02, -7.2280e-02,  4.4813e-03,  ..., -3.8367e-01,\n",
      "          -5.7630e-02,  4.7180e-02],\n",
      "         [ 1.0686e-01, -8.8027e-02, -1.6320e-02,  ..., -4.1772e-01,\n",
      "          -8.8138e-02,  4.7219e-02],\n",
      "         [ 1.4261e-01, -1.1742e-01, -4.2184e-03,  ..., -4.1036e-01,\n",
      "          -1.2604e-01,  6.1625e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.7828e-02, -9.6514e-02,  3.3930e-03,  ..., -3.1585e-01,\n",
      "          -4.0704e-02,  7.9877e-02],\n",
      "         [ 1.3359e-02, -1.6409e-01, -2.6220e-02,  ..., -3.5093e-01,\n",
      "           1.0684e-03,  7.1554e-02],\n",
      "         [ 9.9708e-02, -1.9627e-01, -9.9108e-03,  ..., -3.5587e-01,\n",
      "          -1.4573e-02,  8.6417e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6068e-02, -5.2608e-02, -5.3900e-02,  ..., -2.4826e-01,\n",
      "          -5.4882e-02,  8.9801e-02],\n",
      "         [ 1.4771e-02, -6.0220e-02, -8.2018e-02,  ..., -3.2661e-01,\n",
      "          -6.9712e-02,  1.4334e-01],\n",
      "         [ 5.8446e-03, -4.9690e-02, -1.1439e-01,  ..., -3.0724e-01,\n",
      "          -7.6937e-02,  1.0596e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 6.7280e-02, -3.1616e-02, -9.9450e-02,  ..., -3.9013e-01,\n",
      "          -5.7010e-02,  5.7249e-02],\n",
      "         [ 7.5052e-02, -8.3918e-02, -6.3251e-02,  ..., -3.9352e-01,\n",
      "          -7.9738e-02,  1.0921e-01],\n",
      "         [-2.5844e-02, -1.6713e-01, -1.0216e-01,  ..., -4.3796e-01,\n",
      "          -5.5908e-02,  5.9996e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-9.2383e-03, -7.6346e-02, -4.1446e-02,  ..., -3.5981e-01,\n",
      "          -1.7864e-02,  4.9976e-02],\n",
      "         [ 4.9532e-02, -1.7906e-01, -5.9376e-02,  ..., -3.8705e-01,\n",
      "          -3.4273e-02,  5.0430e-02],\n",
      "         [ 6.9166e-02, -1.8788e-01, -6.4526e-02,  ..., -3.2435e-01,\n",
      "          -2.6383e-02,  1.1428e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/6961 [00:02<28:58,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 9.4465e-02, -5.3647e-02,  1.4391e-02,  ..., -2.0772e-01,\n",
      "          -3.0188e-02,  5.5060e-02],\n",
      "         [ 1.3510e-01, -1.1195e-01,  2.0854e-02,  ..., -2.9457e-01,\n",
      "          -4.7670e-02,  9.0298e-02],\n",
      "         [ 1.7894e-01, -1.2530e-01, -1.8627e-02,  ..., -2.4906e-01,\n",
      "          -9.1842e-02,  1.4543e-01],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 8.8060e-02, -1.2028e-01,  1.3951e-02,  ..., -2.5421e-01,\n",
      "          -6.2799e-02, -2.8286e-02],\n",
      "         [ 2.1873e-02, -2.0083e-01, -2.0076e-02,  ..., -2.8618e-01,\n",
      "          -9.7565e-02, -1.1445e-02],\n",
      "         [ 3.9689e-02, -1.5654e-01, -3.4667e-02,  ..., -3.1555e-01,\n",
      "          -8.5503e-02,  3.5358e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 8.1068e-02, -7.5862e-02, -2.3497e-02,  ..., -3.7614e-01,\n",
      "          -3.9069e-02,  7.0072e-02],\n",
      "         [ 3.3175e-02, -1.5050e-01, -4.9275e-02,  ..., -4.3945e-01,\n",
      "          -2.0269e-02,  5.2031e-02],\n",
      "         [ 4.0333e-02, -1.8129e-01, -7.3209e-02,  ..., -4.6160e-01,\n",
      "          -1.0732e-02,  1.8795e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0322e-02, -6.3473e-02, -1.3401e-02,  ..., -2.8069e-01,\n",
      "          -9.2002e-02,  5.1418e-02],\n",
      "         [ 2.2756e-02, -1.2954e-01, -9.7909e-04,  ..., -3.0951e-01,\n",
      "          -6.7167e-02,  5.5245e-02],\n",
      "         [ 1.0113e-01, -1.4964e-01,  4.6104e-03,  ..., -3.4960e-01,\n",
      "          -5.4125e-02, -5.9834e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-5.2810e-03, -3.7450e-02, -5.6479e-02,  ..., -1.9293e-01,\n",
      "          -3.4143e-02,  4.4594e-02],\n",
      "         [ 1.1118e-02, -8.9864e-02, -2.5591e-02,  ..., -1.5171e-01,\n",
      "          -5.6376e-02,  4.1515e-02],\n",
      "         [ 1.9965e-02, -1.1071e-01, -6.9310e-02,  ..., -2.2801e-01,\n",
      "          -5.4913e-02,  4.5864e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-1.5359e-02, -6.1845e-02, -1.8936e-02,  ..., -3.2969e-01,\n",
      "          -2.8457e-02,  8.0304e-02],\n",
      "         [-1.2625e-02, -1.3307e-01, -3.9638e-02,  ..., -3.2772e-01,\n",
      "          -1.2825e-02,  6.6059e-02],\n",
      "         [-5.9449e-04, -1.6229e-01, -4.8278e-02,  ..., -3.4030e-01,\n",
      "          -4.9383e-02,  5.2228e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/6961 [00:02<28:10,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[-2.6300e-02, -7.8598e-02, -7.9521e-02,  ..., -3.7943e-01,\n",
      "          -6.3086e-02,  1.2492e-01],\n",
      "         [-3.5541e-02, -1.5821e-01, -5.8678e-02,  ..., -4.3739e-01,\n",
      "          -9.1702e-02,  1.4066e-01],\n",
      "         [-3.5026e-02, -1.4962e-01, -3.5156e-02,  ..., -4.2144e-01,\n",
      "          -7.6029e-02,  5.5346e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-1.4169e-02, -8.0202e-02,  5.5179e-02,  ..., -3.0053e-01,\n",
      "          -1.2345e-01, -2.7609e-02],\n",
      "         [ 7.8908e-02, -1.0439e-01,  4.3153e-02,  ..., -3.0148e-01,\n",
      "          -1.1762e-01, -3.6248e-02],\n",
      "         [ 7.9113e-02, -1.6907e-01,  3.5589e-02,  ..., -3.5080e-01,\n",
      "          -1.3692e-01, -4.3541e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.3677e-02, -8.3359e-02, -1.0889e-03,  ..., -2.7747e-01,\n",
      "          -7.1881e-02,  3.3153e-02],\n",
      "         [ 9.8799e-02, -6.9605e-02, -2.8458e-02,  ..., -2.5139e-01,\n",
      "          -4.6581e-02,  2.0676e-02],\n",
      "         [ 6.8187e-02, -1.4010e-01, -7.7774e-02,  ..., -2.0669e-01,\n",
      "          -1.1443e-02,  3.0047e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.0722e-02, -1.0400e-01,  2.4035e-02,  ..., -3.9703e-01,\n",
      "          -5.4091e-02, -5.3931e-03],\n",
      "         [ 8.0841e-02, -1.6763e-01, -2.9624e-03,  ..., -3.4296e-01,\n",
      "          -8.4667e-02,  7.1994e-03],\n",
      "         [ 8.8923e-02, -1.9510e-01,  4.5440e-03,  ..., -4.0491e-01,\n",
      "          -8.1795e-02,  1.3955e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 5.0232e-02, -1.1730e-01, -6.7499e-03,  ..., -2.2337e-01,\n",
      "          -8.8281e-02,  2.5955e-02],\n",
      "         [ 5.3601e-02, -1.0209e-01, -1.9234e-02,  ..., -2.1539e-01,\n",
      "          -8.5599e-02,  4.3821e-02],\n",
      "         [ 4.7647e-02, -1.4823e-01, -6.0111e-02,  ..., -2.6784e-01,\n",
      "          -9.4946e-02,  1.9123e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.0820e-02, -1.0478e-01, -6.7326e-02,  ..., -3.4331e-01,\n",
      "           2.0142e-02,  1.0162e-01],\n",
      "         [ 6.5578e-02, -1.2223e-01,  3.8959e-03,  ..., -3.2311e-01,\n",
      "           1.3787e-02,  3.8555e-02],\n",
      "         [ 4.1501e-02, -2.0241e-01, -4.3367e-02,  ..., -3.0293e-01,\n",
      "          -1.6551e-02,  3.5644e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/6961 [00:02<27:22,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 4.3107e-02, -6.3620e-02, -6.2357e-02,  ..., -6.6978e-02,\n",
      "           5.3601e-05, -4.1554e-03],\n",
      "         [ 1.2239e-01, -1.2494e-02, -5.2563e-02,  ..., -3.2205e-02,\n",
      "          -4.6096e-02, -1.2819e-02],\n",
      "         [ 9.7619e-02,  2.2955e-02, -1.0485e-01,  ..., -5.7082e-02,\n",
      "          -9.2293e-02,  3.0589e-03],\n",
      "         ...,\n",
      "         [ 1.8369e-01, -6.2225e-02, -1.0678e-01,  ..., -7.4750e-02,\n",
      "          -1.4949e-01,  5.7815e-02],\n",
      "         [ 1.8165e-01, -3.3641e-02, -7.1599e-02,  ..., -6.0752e-02,\n",
      "          -4.1972e-02,  3.8667e-02],\n",
      "         [ 1.7802e-01, -1.6791e-02, -5.0243e-02,  ..., -6.1464e-02,\n",
      "          -8.3718e-02,  1.9890e-02]],\n",
      "\n",
      "        [[ 2.1516e-02, -1.7461e-02, -3.8245e-03,  ..., -9.7187e-02,\n",
      "           1.9869e-02,  2.3209e-02],\n",
      "         [ 2.8812e-02,  1.5410e-02, -2.5423e-03,  ..., -1.1733e-01,\n",
      "          -3.6319e-02,  3.5786e-02],\n",
      "         [ 4.1393e-02, -2.4483e-02,  1.3459e-02,  ..., -9.7320e-02,\n",
      "          -4.6189e-02,  3.3697e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.2997e-02, -2.1473e-02,  2.4596e-02,  ..., -1.2052e-01,\n",
      "          -1.6176e-02,  2.5404e-02],\n",
      "         [ 7.3099e-02, -9.7676e-02,  1.7280e-02,  ..., -1.1522e-01,\n",
      "          -3.0938e-03, -4.5512e-03],\n",
      "         [ 1.0386e-01, -1.1201e-01,  5.4846e-02,  ..., -1.1329e-01,\n",
      "          -1.0601e-02,  4.8538e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2637e-03, -2.3552e-02, -3.5801e-02,  ..., -2.9347e-01,\n",
      "          -5.9068e-02,  1.0699e-01],\n",
      "         [ 2.7145e-02, -1.0444e-01, -8.8436e-02,  ..., -2.9282e-01,\n",
      "          -2.6037e-02,  2.9516e-02],\n",
      "         [ 2.3440e-02, -1.0376e-01, -1.8613e-02,  ..., -2.4804e-01,\n",
      "          -3.7498e-02,  3.1872e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.3565e-02,  9.8537e-03, -1.3548e-02,  ..., -1.2706e-01,\n",
      "          -4.1332e-04,  4.1653e-02],\n",
      "         [ 4.4331e-02, -2.4266e-02,  1.2798e-02,  ..., -1.8122e-01,\n",
      "          -3.6066e-02,  4.6425e-02],\n",
      "         [ 1.0324e-01, -9.3387e-02, -5.3644e-02,  ..., -1.1431e-01,\n",
      "          -5.3686e-03,  9.6583e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.0109e-02, -1.1925e-01, -8.8616e-02,  ..., -1.4958e-01,\n",
      "          -1.4684e-01, -1.0895e-02],\n",
      "         [ 4.7732e-02, -1.2671e-01, -3.3827e-02,  ..., -1.8349e-01,\n",
      "          -1.0002e-01, -2.6740e-02],\n",
      "         [ 1.5382e-01, -1.3812e-01, -1.7350e-02,  ..., -1.7827e-01,\n",
      "          -9.1007e-02, -2.4766e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/6961 [00:03<26:40,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 3.4095e-02, -5.3203e-02, -3.0383e-02,  ..., -2.2888e-01,\n",
      "          -9.1916e-02,  7.0748e-02],\n",
      "         [ 4.2636e-02, -1.1759e-01, -5.6108e-02,  ..., -2.3416e-01,\n",
      "          -7.8600e-02,  4.8989e-02],\n",
      "         [ 5.0310e-02, -1.6333e-01, -2.9121e-02,  ..., -2.5780e-01,\n",
      "          -7.8960e-02,  2.8924e-02],\n",
      "         ...,\n",
      "         [ 1.3985e-01, -1.7168e-01,  4.7054e-02,  ..., -1.6951e-01,\n",
      "          -4.4514e-02,  3.8261e-02],\n",
      "         [ 1.2797e-01, -1.8616e-01,  6.3303e-02,  ..., -7.4758e-02,\n",
      "          -7.7028e-02,  1.8959e-02],\n",
      "         [ 1.3476e-01, -2.0361e-01,  4.9514e-02,  ..., -5.5910e-02,\n",
      "          -6.6758e-02,  3.1101e-04]],\n",
      "\n",
      "        [[ 2.0008e-02, -5.5684e-02,  1.3346e-02,  ..., -3.7621e-01,\n",
      "          -6.7177e-02,  4.3407e-03],\n",
      "         [ 4.6155e-02, -1.8567e-01, -1.0687e-02,  ..., -3.9658e-01,\n",
      "          -3.9718e-02, -1.4234e-03],\n",
      "         [ 4.5103e-02, -2.0878e-01,  4.7493e-04,  ..., -4.1124e-01,\n",
      "          -5.9821e-02, -1.4128e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-9.8809e-03, -1.8865e-02, -9.4529e-03,  ..., -2.7062e-01,\n",
      "          -3.4538e-02, -7.9646e-03],\n",
      "         [ 3.8654e-02, -1.1158e-01, -2.3239e-02,  ..., -3.3061e-01,\n",
      "          -3.2695e-02, -3.3497e-02],\n",
      "         [ 6.0868e-02, -1.4078e-01, -7.8019e-03,  ..., -3.1335e-01,\n",
      "          -6.6466e-02,  1.5879e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.5559e-02, -7.7255e-02, -1.9233e-02,  ..., -3.3028e-01,\n",
      "           9.6455e-04,  1.5036e-02],\n",
      "         [ 7.7147e-02, -8.4157e-02, -6.5249e-02,  ..., -3.6167e-01,\n",
      "          -1.2195e-02, -2.3907e-02],\n",
      "         [ 1.1591e-01, -1.9487e-01, -5.8964e-02,  ..., -2.9667e-01,\n",
      "          -3.6174e-02, -3.4243e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 1.5348e-02, -1.3062e-01, -5.0812e-02,  ..., -2.5974e-01,\n",
      "          -1.8092e-02, -1.9889e-02],\n",
      "         [ 2.8696e-02, -1.8984e-01, -7.9210e-02,  ..., -2.9709e-01,\n",
      "          -2.4284e-02,  3.5288e-03],\n",
      "         [ 4.9783e-02, -1.8105e-01, -7.1164e-02,  ..., -3.0746e-01,\n",
      "          -3.5879e-03,  8.0128e-03],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 2.6282e-02, -1.4108e-01, -8.4182e-04,  ..., -3.3699e-01,\n",
      "          -1.0810e-01, -1.1061e-02],\n",
      "         [-1.6285e-02, -1.9483e-01, -4.7936e-02,  ..., -3.1957e-01,\n",
      "          -8.8800e-02,  4.0521e-02],\n",
      "         [-6.2050e-04, -2.7735e-01, -5.1928e-02,  ..., -3.8178e-01,\n",
      "          -3.5187e-02,  1.5000e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/6961 [00:03<32:11,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]],\n",
      "\n",
      "        [[    -0.],\n",
      "         [    -0.],\n",
      "         [    -0.],\n",
      "         ...,\n",
      "         [-10000.],\n",
      "         [-10000.],\n",
      "         [-10000.]]], device='cuda:4') tensor([[[ 2.5090e-02, -2.7420e-02, -2.3216e-02,  ..., -2.4549e-01,\n",
      "          -7.0854e-02,  6.7338e-02],\n",
      "         [-2.4378e-02, -1.1291e-01, -2.1170e-02,  ..., -2.8586e-01,\n",
      "          -5.7935e-02,  1.0267e-01],\n",
      "         [-2.4720e-02, -1.3976e-01, -1.0567e-01,  ..., -3.6872e-01,\n",
      "          -6.7454e-02,  6.3926e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 3.2279e-02, -8.9084e-02, -5.1385e-02,  ..., -2.7613e-01,\n",
      "          -7.5602e-02,  7.7362e-02],\n",
      "         [ 9.5305e-02, -1.5521e-01, -5.1508e-02,  ..., -2.3895e-01,\n",
      "          -1.8502e-02,  7.0895e-02],\n",
      "         [ 8.7048e-02, -2.1552e-01, -5.4963e-02,  ..., -2.5588e-01,\n",
      "          -6.0168e-02,  7.0278e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[ 1.4768e-02, -1.0740e-01, -1.0483e-02,  ..., -1.5096e-01,\n",
      "          -2.8787e-02, -1.1671e-02],\n",
      "         [ 3.9786e-04, -1.6092e-01, -1.7371e-02,  ..., -1.7565e-01,\n",
      "          -3.4987e-02,  3.6969e-02],\n",
      "         [ 7.3220e-03, -1.8298e-01,  8.6705e-03,  ..., -2.0201e-01,\n",
      "          -3.9412e-02,  8.9370e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.0034e-02, -8.5733e-02,  1.8224e-02,  ..., -3.7915e-01,\n",
      "          -4.3753e-02, -4.4787e-02],\n",
      "         [-3.3660e-02, -1.7365e-01,  1.8103e-02,  ..., -3.3305e-01,\n",
      "          -4.2290e-02, -3.0024e-02],\n",
      "         [-4.5972e-02, -2.2573e-01,  1.8480e-02,  ..., -3.7228e-01,\n",
      "          -4.1190e-02, -2.7987e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-3.7251e-02, -3.7219e-02, -4.6998e-03,  ..., -2.6863e-01,\n",
      "          -6.0190e-02, -6.6828e-05],\n",
      "         [-4.7709e-02, -1.0215e-01, -3.9929e-02,  ..., -3.5777e-01,\n",
      "          -7.3397e-02, -1.9507e-02],\n",
      "         [-3.8220e-02, -1.6214e-01, -1.6003e-02,  ..., -4.1149e-01,\n",
      "          -6.9221e-02, -2.6145e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]],\n",
      "\n",
      "        [[-8.1508e-03, -1.0260e-01, -4.2139e-02,  ..., -4.0587e-01,\n",
      "          -3.2260e-03,  4.6251e-02],\n",
      "         [ 3.5969e-02, -1.8609e-01, -8.0777e-03,  ..., -4.0722e-01,\n",
      "          -6.6933e-02,  4.2248e-02],\n",
      "         [ 4.0582e-02, -2.3020e-01, -5.3771e-02,  ..., -4.4904e-01,\n",
      "          -3.5947e-02,  5.1490e-02],\n",
      "         ...,\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04],\n",
      "         [-1.0000e+04, -1.0000e+04, -1.0000e+04,  ..., -1.0000e+04,\n",
      "          -1.0000e+04, -1.0000e+04]]], device='cuda:4', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-243a11795418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#         if epoch<2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#             scheduler_warm.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim, y_truth = batch\n",
    "        y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "        optimizer.zero_grad()\n",
    "                                 \n",
    "        loss = loss_fn(y_pred, y_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "#         if epoch<2:\n",
    "#             scheduler_warm.step()\n",
    "# target.view(target.size(0), 1).long()\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    valid_preds_fold = np.zeros((valid_label.size(0), 10))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    acc, f1 = metric(valid_label, np.argmax(valid_preds_fold, axis=1))\n",
    "    if best_acc <= acc:\n",
    "        early_stop = 0\n",
    "        best_acc = acc\n",
    "        valid_best = valid_preds_fold\n",
    "        # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "        # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "        torch.save(model.state_dict(), train_root+'lstm_age_trf9.bin')\n",
    "    else:\n",
    "        early_stop += 1\n",
    "    print(\n",
    "        'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_acc: %.8f\\n' %\n",
    "        (epoch, train_loss, val_loss, acc, f1, best_acc))\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if early_stop >= patience:\n",
    "#         break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            if param_group['lr']>=3e-5:\n",
    "                param_group['lr'] *= 0.3\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:#copy4 0.4862,0.4884\n",
    "        param_group['lr']=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2020.5.12\n",
    "0.39 0.92\n",
    "V1    age n_vocab不冻结0.39√    gender n_vocab 冻结 \n",
    "n_vocab在目前情况下看来不是效果很好\n",
    "V2    age all冻结 0.4528   gender all冻结0.9432\n",
    "V3    age cre与adv  lr-3 0.46 0.470 lr-4 0.4760   \n",
    "V4    age cre-adv-ind lr-4 0.4768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>351878 103064 665090 593698 1508864 1797787 17...</td>\n",
       "      <td>7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>3 11 11 23 29 49 49 49 54 54 82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>152519 151984 176984 12838 72773 64667 81234 7...</td>\n",
       "      <td>12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...</td>\n",
       "      <td>1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>161840 367084 36634 115761 73137 150407 41212 ...</td>\n",
       "      <td>22367_82_319_2 40491_34504_202_5 22338_2065_23...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>108656 849706 678427 9870 157180 94025 907546 ...</td>\n",
       "      <td>8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>123860 183003 40625 26793 71219 259607 167448 ...</td>\n",
       "      <td>30710_1896_238_2 29243_1987_26_2 23746_129_6_2...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>172004 237425 54100 417864 282643 30856 116356...</td>\n",
       "      <td>10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...</td>\n",
       "      <td>1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>271727 390953 914417 641757 50445 14993 793940...</td>\n",
       "      <td>10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>100456 464055 54150 316582 882346 882346 77124...</td>\n",
       "      <td>23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>273715 95215 146101 117043 840 366940 148209 7...</td>\n",
       "      <td>37660_\\N_322_18 22626_1062_238_2 20528_1492_32...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>250735 253460 333302 291416 231478 58631 11040...</td>\n",
       "      <td>30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...</td>\n",
       "      <td>2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        creative_id  \\\n",
       "0       3000001  351878 103064 665090 593698 1508864 1797787 17...   \n",
       "1       3000002  152519 151984 176984 12838 72773 64667 81234 7...   \n",
       "2       3000003  161840 367084 36634 115761 73137 150407 41212 ...   \n",
       "3       3000004  108656 849706 678427 9870 157180 94025 907546 ...   \n",
       "4       3000005  123860 183003 40625 26793 71219 259607 167448 ...   \n",
       "...         ...                                                ...   \n",
       "999995  3999996  172004 237425 54100 417864 282643 30856 116356...   \n",
       "999996  3999997  271727 390953 914417 641757 50445 14993 793940...   \n",
       "999997  3999998  100456 464055 54150 316582 882346 882346 77124...   \n",
       "999998  3999999  273715 95215 146101 117043 840 366940 148209 7...   \n",
       "999999  4000000  250735 253460 333302 291416 231478 58631 11040...   \n",
       "\n",
       "                                                  uni_col  \\\n",
       "0       7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...   \n",
       "1       12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...   \n",
       "2       22367_82_319_2 40491_34504_202_5 22338_2065_23...   \n",
       "3       8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...   \n",
       "4       30710_1896_238_2 29243_1987_26_2 23746_129_6_2...   \n",
       "...                                                   ...   \n",
       "999995  10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...   \n",
       "999996  10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...   \n",
       "999997  23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...   \n",
       "999998  37660_\\N_322_18 22626_1062_238_2 20528_1492_32...   \n",
       "999999  30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...   \n",
       "\n",
       "                                              click_times  \\\n",
       "0                                   1 1 1 1 1 1 1 1 1 1 1   \n",
       "1       1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3                 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "4       1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                   ...   \n",
       "999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...   \n",
       "999996            1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999997              1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999998  1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...   \n",
       "999999  2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                     time  \n",
       "0                         3 11 11 23 29 49 49 49 54 54 82  \n",
       "1       9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...  \n",
       "2       1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...  \n",
       "3       13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...  \n",
       "4       2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...  \n",
       "...                                                   ...  \n",
       "999995  1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...  \n",
       "999996  2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...  \n",
       "999997  4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...  \n",
       "999998  2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...  \n",
       "999999  1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_group = pd.read_csv(test_root+'test_trf.csv',index_col=0)\n",
    "test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1259/1000000 [00:00<03:00, 5545.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[111563, 1182, 46816, 21269, 2050, 1834, 1289, 1971, 102895, 37550, 4012, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [605, 185, 490, 8986, 711, 711, 158, 342, 6232, 6279, 868, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 11, 11, 23, 29, 49, 49, 49, 54, 54, 82, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:07<00:00, 7832.43it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1465306.65it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1281015.65it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1440010.44it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1286721.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 47s, sys: 13.9 s, total: 7min 1s\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_examples, test_df = read_examples(test_group, is_training=False)\n",
    "test_features = convert_examples_to_features(test_examples, vocab, max_seq_length)\n",
    "\n",
    "test_input_cre = torch.tensor(np.array([test_feature.feature['creative']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_uni = torch.tensor(np.array([test_feature.feature['uni_col']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_clk = torch.tensor(np.array([test_feature.feature['click_times']  for test_feature in tqdm(test_features)]), dtype=torch.float32)\n",
    "test_input_tim = torch.tensor(np.array([test_feature.feature['time']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(test_input_cre, test_input_uni,test_input_clk,test_input_tim)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (embedding_cre): Embedding(4445721, 300)\n",
       "  (embedding_uni): Embedding(110810, 100)\n",
       "  (embeddingLN): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "  (postion_embedding): Positional_Encoding(\n",
       "    (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (embedding_pos): Embedding(92, 400)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attention): Multi_Head_Attention(\n",
       "      (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (attention): Scaled_Dot_Product_Attention()\n",
       "      (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (feed_forward): Position_wise_Feed_Forward(\n",
       "      (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (attention): Multi_Head_Attention(\n",
       "        (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (attention): Scaled_Dot_Product_Attention()\n",
       "        (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward): Position_wise_Feed_Forward(\n",
       "        (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "        (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(400, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=98, stride=98, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(3)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age1.bin'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7813 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 7813/7813 [08:16<00:00, 15.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.90295260e-02, 5.87537408e-01, 3.39540720e-01, ...,\n",
       "        1.10562733e-05, 5.03552155e-06, 1.02033812e-06],\n",
       "       [4.61107629e-05, 3.16065439e-06, 2.79334336e-06, ...,\n",
       "        2.14797795e-01, 1.85888421e-04, 2.66915572e-06],\n",
       "       [2.20072875e-03, 1.89610466e-01, 2.34682947e-01, ...,\n",
       "        5.97620674e-04, 6.77099961e-05, 4.23706988e-05],\n",
       "       ...,\n",
       "       [1.50729358e-01, 7.54850090e-01, 9.39997584e-02, ...,\n",
       "        7.05929040e-07, 4.42586469e-07, 2.23300944e-07],\n",
       "       [3.68597481e-04, 3.28052223e-01, 6.70274436e-01, ...,\n",
       "        1.45324478e-07, 8.01207491e-08, 1.86131359e-08],\n",
       "       [1.08797918e-04, 2.18730792e-03, 1.01299472e-02, ...,\n",
       "        5.63489084e-05, 1.33069682e-06, 6.83924611e-07]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_fold = np.zeros((len(test_df), 10))\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre, x_uni, x_clk,x_tim= batch\n",
    "        y_pred = model(x_cre, x_uni, x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "# test_preds_fold = np.argmax(test_preds_fold, axis=1)+1\n",
    "test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000002</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000003</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000004</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000005</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999999</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predicted_age  predicted_gender\n",
       "user_id                                 \n",
       "3000001              3                 0\n",
       "3000002              7                 0\n",
       "3000003              2                 0\n",
       "3000004              3                 0\n",
       "3000005              4                 0\n",
       "...                ...               ...\n",
       "3999996              3                 0\n",
       "3999997              2                 0\n",
       "3999998              2                 0\n",
       "3999999              3                 0\n",
       "4000000              5                 0\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = test_preds_fold\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log2(a+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b882e48eecc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([0],dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
