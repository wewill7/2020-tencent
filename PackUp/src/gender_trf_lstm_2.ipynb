{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train_semi_final/'\n",
    "test_root = './data/test/'\n",
    "# ad = pd.read_csv(train_root+'ad.csv')\n",
    "# click_log = pd.read_csv(train_root +'click_log.csv')\n",
    "# user = pd.read_csv(train_root+'user.csv')\n",
    "# Tclick_log = pd.read_csv(test_root +'click_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445721 4445721\n",
      "110810 110810\n"
     ]
    }
   ],
   "source": [
    "pre_embedding_cre = np.load(train_root+'creative_id_w2v_300d.npy')\n",
    "pre_vocab_cre = json.load(open(train_root+'creative_id_vocab_300d.json','r'))\n",
    "pre_vocab_cre.update({'_PAD_':len(pre_vocab_cre)})\n",
    "pre_embedding_cre = np.concatenate((pre_embedding_cre,np.zeros((1,300)) ))\n",
    "print(len(pre_embedding_cre),len(pre_vocab_cre))\n",
    "\n",
    "pre_embedding_uni = np.load(train_root+'uni_col_w2v_100d.npy')\n",
    "pre_vocab_uni = json.load(open(train_root+'uni_col_vocab_100d.json','r'))\n",
    "pre_vocab_uni.update({'_PAD_':len(pre_vocab_uni)})\n",
    "pre_embedding_uni = np.concatenate((pre_embedding_uni,np.zeros((1,100)) ))\n",
    "print(len(pre_embedding_uni),len(pre_vocab_uni))\n",
    "\n",
    "vocab = {\n",
    "    'creative':pre_vocab_cre,\n",
    "    'uni_col':pre_vocab_uni,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 s, sys: 2.33 s, total: 34.1 s\n",
      "Wall time: 34.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>821396 877468 209778 1683713 122032 71691 1940...</td>\n",
       "      <td>7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2</td>\n",
       "      <td>20 20 20 39 40 43 46 52 60 64 64 73 76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63441 155822 39714 609050 13069 441462 1266180...</td>\n",
       "      <td>22885_87_318_2 10686_80_238_2 18562_129_6_2 25...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>661347 808612 593522 825434 710859 726940 3920...</td>\n",
       "      <td>32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39588 589886 574787 1892854 1230094 2264105 31...</td>\n",
       "      <td>19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>296145 350759 24333 43235 852327 1054434 12964...</td>\n",
       "      <td>11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999996</td>\n",
       "      <td>190253 309607 1099 567833 571808 33159 1560316...</td>\n",
       "      <td>14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999997</td>\n",
       "      <td>20588 351431 15563 395549 169325 530723 43044 ...</td>\n",
       "      <td>11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999998</td>\n",
       "      <td>642652 932655 670 6508 944753 3507884 3123952 ...</td>\n",
       "      <td>29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>16 22 66 80 83 84 85 88 89 89 90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999999</td>\n",
       "      <td>69204 602554 498385 69204 2293419 3007031 2996...</td>\n",
       "      <td>24952_26858_60_3 28581_35561_\\N_4 28874_26858_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>3000000</td>\n",
       "      <td>44891 48221 17705 51330 192726 192492 192492 1...</td>\n",
       "      <td>20794_145_60_2 20794_145_60_2 17960_145_60_2 1...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                        creative_id  \\\n",
       "0              1  821396 877468 209778 1683713 122032 71691 1940...   \n",
       "1              2  63441 155822 39714 609050 13069 441462 1266180...   \n",
       "2              3  661347 808612 593522 825434 710859 726940 3920...   \n",
       "3              4  39588 589886 574787 1892854 1230094 2264105 31...   \n",
       "4              5  296145 350759 24333 43235 852327 1054434 12964...   \n",
       "...          ...                                                ...   \n",
       "2999995  2999996  190253 309607 1099 567833 571808 33159 1560316...   \n",
       "2999996  2999997  20588 351431 15563 395549 169325 530723 43044 ...   \n",
       "2999997  2999998  642652 932655 670 6508 944753 3507884 3123952 ...   \n",
       "2999998  2999999  69204 602554 498385 69204 2293419 3007031 2996...   \n",
       "2999999  3000000  44891 48221 17705 51330 192726 192492 192492 1...   \n",
       "\n",
       "                                                   uni_col  \\\n",
       "0        7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...   \n",
       "1        22885_87_318_2 10686_80_238_2 18562_129_6_2 25...   \n",
       "2        32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...   \n",
       "3        19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...   \n",
       "4        11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...   \n",
       "...                                                    ...   \n",
       "2999995  14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...   \n",
       "2999996  11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...   \n",
       "2999997  29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...   \n",
       "2999998  24952_26858_60_3 28581_35561_\\N_4 28874_26858_...   \n",
       "2999999  20794_145_60_2 20794_145_60_2 17960_145_60_2 1...   \n",
       "\n",
       "                                               click_times  \\\n",
       "0                                1 1 1 1 1 1 1 1 1 1 1 1 2   \n",
       "1        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "4        1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                    ...   \n",
       "2999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2999996  1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...   \n",
       "2999997                              1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999998              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999999  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                      time  age  gender  \n",
       "0                   20 20 20 39 40 43 46 52 60 64 64 73 76    4       1  \n",
       "1        10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...   10       1  \n",
       "2        12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...    7       2  \n",
       "3        8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...    5       1  \n",
       "4        3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...    4       1  \n",
       "...                                                    ...  ...     ...  \n",
       "2999995  1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...    4       2  \n",
       "2999996  3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...    2       2  \n",
       "2999997                   16 22 66 80 83 84 85 88 89 89 90    4       2  \n",
       "2999998  7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...    3       2  \n",
       "2999999  1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...    8       2  \n",
       "\n",
       "[3000000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_root+'train_trf.csv',index_col = 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, uid, creative, uni_col,click_times, time, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            id: Unique id for the example.\n",
    "            text: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.id = uid\n",
    "        self.text = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 feature,\n",
    "                 label\n",
    "                 ):\n",
    "        self.example_id = example_id\n",
    "        creative, uni_col, click_times, time = feature\n",
    "        self.feature = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "def read_examples(df, is_training):\n",
    "    if not is_training:\n",
    "        df['label'] = np.zeros(len(df), dtype=np.int64)\n",
    "    examples = []\n",
    "    for idex, row in df.iterrows():\n",
    "        if is_training:\n",
    "            label = row['gender']\n",
    "        else:\n",
    "            label = row['label']\n",
    "        examples.append(InputExample(uid=idex, creative=row['creative_id'], uni_col =row['uni_col'], \n",
    "                                     click_times=row['click_times'], time = row['time'], label=label-1))\n",
    "    return examples, df\n",
    "\n",
    "def convert_examples_to_features(examples, word_to_id, max_seq_length):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        #!!!!!!!!!!!!!!!!!!!##\n",
    "        content=['creative','uni_col']\n",
    "        feature=[]\n",
    "        for onekind in content:\n",
    "            tokens_text = example.text[onekind].split()\n",
    "            tokens=[]\n",
    "            for token_text in tokens_text:\n",
    "                if token_text in word_to_id[onekind]:\n",
    "                    tokens.append(token_text)\n",
    "                else:\n",
    "                    tokens.append('_PAD_')\n",
    "            if len(tokens)>=max_seq_length:\n",
    "                tokens = tokens[:max_seq_length]\n",
    "            else:\n",
    "                tokens += ['_PAD_']*(max_seq_length-len(tokens))\n",
    "            token_ids = [word_to_id[onekind][token] for token in tokens]\n",
    "            feature.append(token_ids)\n",
    "        ###for click_times\n",
    "        tokens_text = example.text['click_times'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "            if int(token_text)<=4:\n",
    "                tokens.append(int(token_text))\n",
    "            else:\n",
    "                tokens.append(1)\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "        ###for time\n",
    "        tokens_text = example.text['time'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "                tokens.append(int(token_text))\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "            \n",
    "        \n",
    "        label = example.label\n",
    "\n",
    "        if example_index < 1:\n",
    "            print(example.id,'/n',feature,'/n',label)\n",
    "#             logger.info(\"*** Example ***\")\n",
    "#             logger.info(\"idx: {}\".format(example_index))\n",
    "#             logger.info(\"id: {}\".format(example.id))\n",
    "#             logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
    "#             logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
    "#             logger.info(\"input_mask: {}\".format(len(input_mask)))\n",
    "#             logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n",
    "#             logger.info(\"label: {}\".format(label))\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id=example.id,\n",
    "                feature= feature,\n",
    "                label=label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_class=10,dim=400,num_head=4,hidden=1024,dropout=0.1,max_seq_length=64):\n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_cre = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_cre,dtype=torch.float32), freeze=True)\n",
    "        self.embedding_uni = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_uni,dtype=torch.float32), freeze=True)\n",
    "        self.embeddingLN = nn.LayerNorm(dim, elementwise_affine=True)\n",
    "\n",
    "        self.postion_embedding = Positional_Encoding(dim)\n",
    "        self.encoder = Encoder(dim,num_head,hidden,dropout)#config.dim_model, config.num_head, config.hidden, config.dropout\n",
    "        self.encoders = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder)\n",
    "            # Encoder(config.dim_model, config.num_head, config.hidden, config.dropout)\n",
    "            for _ in range(1)])#config.num_encoder\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=400, hidden_size=768, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=0.5 )\n",
    "#         self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "        # self.fc1 = nn.Linear(config.pad_size * config.dim_model, config.num_classes)\n",
    "        # self.fc2 = nn.Linear(config.last_hidden, config.num_classes)\n",
    "        # self.fc1 = nn.Linear(config.dim_model, config.num_classes)\n",
    "        self.maxpool = nn.MaxPool1d(max_seq_length)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, cre, uni, clk, time):\n",
    "        x_cre = self.embedding_cre(cre)\n",
    "        x_uni = self.embedding_uni(uni)\n",
    "        x = torch.cat((x_cre, x_uni), 2)\n",
    "        x = self.embeddingLN(x)\n",
    "\n",
    "        out_trf = self.postion_embedding(x, time)\n",
    "        mask = clk.unsqueeze(1).expand(clk.size(0), clk.size(1), clk.size(1))#batch*seq*seq\n",
    "        for encoder in self.encoders:\n",
    "            out_trf = encoder(out_trf, mask)\n",
    "\n",
    "\n",
    "        pad = torch.clamp(clk,0,1).unsqueeze(2)      \n",
    "        out, _ = self.lstm(out_trf*pad)\n",
    "#         out = self.fc(out[:,-1,:])\n",
    "        # out = out.view(out.size(0), -1)#batch *seq*dim\n",
    "        # # out = torch.mean(out, 1)\n",
    "        # out = self.fc1(out)\n",
    "#         out = torch.cat((out_trf, out), 2)\n",
    "        out = out+(1-pad)*(-10000)\n",
    "        out = torch.tanh(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.maxpool(out).squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.attention(x, mask)\n",
    "        out = self.feed_forward(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dim = dim_model\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "        pe = torch.tensor([[pos / (10000.0 ** (i // 2 * 2.0 / self.dim)) for i in range(self.dim)] for pos in range(92)],dtype=torch.float32)\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2])\n",
    "        self.embedding_pos = nn.Embedding.from_pretrained(pe, freeze=True)\n",
    "    def forward(self, x, time):\n",
    "\n",
    "        x_pos = self.embedding_pos(time)\n",
    "        out = x + x_pos\n",
    "        out = self.layer_norm(out)\n",
    "#         out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    '''Scaled Dot-Product Attention '''\n",
    "    def __init__(self):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__()\n",
    "#         self.atten_dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, Q, K, V, scale=None, mask =None):\n",
    "\n",
    "        attention = torch.matmul(Q, K.transpose(-1, -2))# scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "        if 1:  # TODO change this\n",
    "            # attention = attention.masked_fill_(mask == 0, -1e9)\n",
    "            attention = attention*torch.log2(1+mask)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        ###L dropout\n",
    "#         attention = self.atten_dropout(attention)\n",
    "        context = torch.matmul(attention, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, dropout=0.1):\n",
    "        super(Multi_Head_Attention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        assert dim_model % num_head == 0\n",
    "        self.dim_head = dim_model // self.num_head\n",
    "        self.fc_Q = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_K = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_V = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.fc = nn.Linear(num_head * self.dim_head, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        batch_size = x.size(0)\n",
    "        Q = self.fc_Q(x)\n",
    "        K = self.fc_K(x)\n",
    "        V = self.fc_V(x)\n",
    "        Q = Q.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        K = K.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "\n",
    "        if 1:  # TODO\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_head, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]  # TODO change this\n",
    "        scale = K.size(-1) ** -0.5  # 缩放因子\n",
    "        context = self.attention(Q, K, V, scale, mask)\n",
    "        #context: [batch_size x len_q x n_heads * d_v]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_head * self.num_head)\n",
    "        out = self.fc(context)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Position_wise_Feed_Forward(nn.Module):\n",
    "    def __init__(self, dim_model, hidden, dropout=0.0):\n",
    "        super(Position_wise_Feed_Forward, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.gelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 158\n",
    "batch_size = 128\n",
    "# tokenizer = jieba.lcut\n",
    "\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 20\n",
    "patience = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "# device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(train, test_size=0.1, random_state=7, shuffle=True,stratify=train.gender.values)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1289/810000 [00:00<02:13, 6043.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462267 /n [[172, 642, 134, 2048, 1047530, 4495, 277, 642, 1074, 768, 93912, 6852, 1931, 6656, 917, 453, 119, 117, 630, 18703, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772], [94, 24, 313, 929, 1095, 2088, 24, 24, 598, 172, 7, 10, 10, 205, 389, 5, 192, 124, 85, 57, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845], [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 12, 12, 12, 13, 13, 13, 15, 15, 19, 22, 36, 36, 40, 57, 61, 64, 64, 72, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810000/810000 [02:04<00:00, 6530.83it/s]\n",
      "  2%|▏         | 1567/90000 [00:00<00:11, 7805.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870872 /n [[81434, 2689785, 156377, 9, 5168, 4192, 2689786, 15041, 38475, 14727, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772, 3412772], [7913, 8815, 390, 3, 526, 111, 111, 112, 111, 281, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845, 98845], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [36, 54, 59, 66, 67, 74, 74, 82, 83, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [00:19<00:00, 4541.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 19s, sys: 10.8 s, total: 5min 30s\n",
      "Wall time: 5min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "valid_examples, valid_df = read_examples(valid, is_training=True)\n",
    "valid_features = convert_examples_to_features(valid_examples, vocab, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810000/810000 [00:00<00:00, 1436406.69it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1239358.85it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1414662.20it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1251871.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "valid_input_cre = torch.tensor(np.array([valid_feature.feature['creative'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_uni = torch.tensor(np.array([valid_feature.feature['uni_col'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_clk= torch.tensor(np.array([valid_feature.feature['click_times'] for valid_feature in valid_features]), dtype=torch.float32)\n",
    "valid_input_tim= torch.tensor(np.array([valid_feature.feature['time'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "valid_label = torch.tensor(np.array([valid_feature.label for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_input_cre,train_input_uni,train_input_clk,train_input_tim, train_label)\n",
    "valid_data = torch.utils.data.TensorDataset(valid_input_cre,valid_input_uni,valid_input_clk,valid_input_tim, valid_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "      Focal_Loss= -1*alpha*(1-pt)^gamma*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "            focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if self.alpha is None:\n",
    "            self.alpha = torch.ones(self.num_class, 1)\n",
    "        elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "            assert len(self.alpha) == self.num_class\n",
    "            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "            self.alpha = self.alpha / self.alpha.sum()\n",
    "        elif isinstance(self.alpha, float):\n",
    "            alpha = torch.ones(self.num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[balance_index] = self.alpha\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        # N = input.size(0)\n",
    "        # alpha = torch.ones(N, self.num_class)\n",
    "        # alpha = alpha * (1 - self.alpha)\n",
    "        # alpha = alpha.scatter_(1, target.long(), self.alpha)\n",
    "        epsilon = 1e-10\n",
    "        alpha = self.alpha\n",
    "        if alpha.device != input.device:\n",
    "            alpha = alpha.to(input.device)\n",
    "\n",
    "        idx = target.cpu().long()\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth, 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "        logpt = pt.log()\n",
    "\n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "#         loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "        loss = -1 * alpha * logpt\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "model = myModel(768,2,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# loss_fn = SmoothLabelCritierion(label_smoothing=0.1)\n",
    "# alpha = np.array([2.0,1.0])\n",
    "# loss_fn = FocalLoss(num_class=2, alpha=alpha)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler_warm= torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step:step/(2*len(train_loader)))\n",
    "\n",
    "best_acc = 0.\n",
    "valid_best = np.zeros((valid_label.size(0), 2))\n",
    "\n",
    "early_stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1195/3000000 [00:00<08:40, 5761.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[369522, 82667, 30791, 54327, 1122, 57, 17354, 2501, 3140, 1903, 18115, 1903, 150654, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [681, 3524, 2153, 2038, 1190, 42, 288, 2059, 880, 886, 847, 886, 17, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [20, 20, 20, 39, 40, 43, 46, 52, 60, 64, 64, 73, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000000/3000000 [09:53<00:00, 5056.48it/s] \n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1162352.27it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1218821.26it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1266689.61it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1224609.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###five fold\n",
    "####\n",
    "\n",
    "# train = pd.read_csv(train_root+'train_creative.csv',index_col = 0)\n",
    "\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "\n",
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "import gc\n",
    "del train\n",
    "del train_df\n",
    "del train_examples\n",
    "del train_features\n",
    "\n",
    "# del test_group\n",
    "# del test_df \n",
    "# del test_examples\n",
    "# del test_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================     fold 2        ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 18750/18750 [1:39:58<00:00,  3.13it/s]\n",
      "4688it [08:01,  9.73it/s]\n",
      "  0%|          | 0/18750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.13726396, valid loss: 0.15013408, acc: 0.94753333, f1: 0.94746696, best_f1: 0.15013408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18750/18750 [1:40:16<00:00,  3.12it/s]\n",
      "4688it [08:03,  9.70it/s]\n",
      "  0%|          | 0/18750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.13683780, valid loss: 0.15021824, acc: 0.94751833, f1: 0.94745424, best_f1: 0.15013408\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 14843/18750 [1:19:16<20:52,  3.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fd68a44a2a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# target.view(target.size(0), 1).long()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###five fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)\n",
    "# off: out-of-fold\n",
    "# oof_test = np.zeros((100_0000, 2), dtype=np.float32)\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(train_label, train_label)):\n",
    "    if fold!=2:\n",
    "        continue\n",
    "\n",
    "    print('================     fold {}        ==============='.format(fold))\n",
    "    train_input_fold_cre = torch.tensor(train_input_cre[train_index], dtype=torch.long)\n",
    "    train_input_fold_uni = torch.tensor(train_input_uni[train_index], dtype=torch.long)\n",
    "    train_input_fold_clk = torch.tensor(train_input_clk[train_index], dtype=torch.float32)\n",
    "    train_input_fold_tim = torch.tensor(train_input_tim[train_index], dtype=torch.long)\n",
    "    train_label_fold = torch.tensor(train_label[train_index], dtype=torch.long)\n",
    "    \n",
    "    valid_input_fold_cre = torch.tensor(train_input_cre[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_uni = torch.tensor(train_input_uni[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_clk = torch.tensor(train_input_clk[valid_index], dtype=torch.float32)\n",
    "    valid_input_fold_tim = torch.tensor(train_input_tim[valid_index], dtype=torch.long)\n",
    "    valid_label_fold = torch.tensor(train_label[valid_index], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    train_data_fold  = torch.utils.data.TensorDataset(train_input_fold_cre,train_input_fold_uni,train_input_fold_clk,train_input_fold_tim, train_label_fold )\n",
    "    valid_data_fold  = torch.utils.data.TensorDataset(valid_input_fold_cre,valid_input_fold_uni,valid_input_fold_clk,valid_input_fold_tim,valid_label_fold )\n",
    "\n",
    "    train_loader_fold  = torch.utils.data.DataLoader(train_data_fold , batch_size=batch_size, shuffle=True)\n",
    "    valid_loader_fold  = torch.utils.data.DataLoader(valid_data_fold , batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "     \n",
    "    del train_input_cre\n",
    "    del train_input_uni\n",
    "    del train_input_clk\n",
    "    del train_input_tim\n",
    "    gc.collect()        \n",
    "    torch.cuda.set_device(3)\n",
    "    model =  myModel(768,2,max_seq_length=max_seq_length)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_gender2.bin'))####TODO\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.035},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    for param_group in optimizer.param_groups:####TODO\n",
    "        param_group['lr']=1e-6\n",
    "\n",
    "    best_val = 10000.\n",
    "    valid_best = np.zeros((valid_label_fold.size(0), 2))\n",
    "\n",
    "    early_stop = 0    \n",
    "    model.train()\n",
    "    \n",
    "    del pre_embedding_cre\n",
    "    del pre_embedding_uni\n",
    "    gc.collect()\n",
    "    for epoch in range(num_epochs):\n",
    "#         if epoch==16:\n",
    "#             model.load_state_dict(torch.load(train_root+'lstm_gender2.bin'))\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr']=1e-6\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        for i, batch in enumerate(tqdm(train_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(y_pred, y_truth)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() / len(train_loader_fold)\n",
    "    # target.view(target.size(0), 1).long()\n",
    "        model.eval()\n",
    "        val_loss = 0.\n",
    "        valid_preds_fold = np.zeros((valid_label_fold.size(0), 2))\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "                y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "                val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "        if best_val >= val_loss:\n",
    "            early_stop = 0\n",
    "            best_val = val_loss\n",
    "            valid_best = valid_preds_fold\n",
    "            # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "            # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "            torch.save(model.state_dict(), train_root+'lstm_gender2.bin')\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        print(\n",
    "            'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (epoch, train_loss, val_loss, acc, f1, best_val))\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if early_stop >= patience:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                if param_group['lr']>=3e-5:\n",
    "                    param_group['lr'] *= 0.3\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(param_group['lr'])\n",
    "\n",
    "            \n",
    "    test_preds_fold = np.zeros((100_0000, 2))\n",
    "    valid_preds_fold = np.zeros((valid_label_fold.size(0), 2))\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_gender2.bin'))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate( tqdm(test_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "    acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "    print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "                (acc, f1, best_val))\n",
    "   \n",
    "    \n",
    "    #oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()    \n",
    "    oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4688it [08:11,  9.55it/s]\n",
      "100%|██████████| 7813/7813 [13:37<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: best, acc: 0.94753333, f1: 0.94746696, best_f1: 0.15013408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "test_preds_fold = np.zeros((100_0000, 2))\n",
    "valid_preds_fold = np.zeros((valid_label_fold.size(0), 2))\n",
    "model.load_state_dict(torch.load(train_root+'lstm_gender2.bin', map_location={'cuda:3':'cuda:1'}))\n",
    "model.eval()\n",
    "# model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "        valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (acc, f1, best_val))\n",
    "\n",
    "\n",
    "#oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "# oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test = np.argmax(oof_test, axis=1)+1\n",
    "oof_test\n",
    "submission = pd.read_csv('submission1.csv', index_col = 0 )\n",
    "submission.predicted_age = oof_test\n",
    "submission\n",
    "submission.to_csv('submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_preds_fold).to_csv('five_gender22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:15<00:00,  3.08it/s]\n",
      "704it [01:12,  9.77it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.14944562, valid loss: 0.15688732, acc: 0.94490000, f1: 0.94480581, best_acc: 0.94490000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:27<00:00,  3.06it/s]\n",
      "704it [01:12,  9.77it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.14893250, valid loss: 0.15676552, acc: 0.94474444, f1: 0.94464074, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:31<00:00,  3.05it/s]\n",
      "704it [01:12,  9.73it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 0.14868612, valid loss: 0.15670611, acc: 0.94480000, f1: 0.94469470, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:46<00:00,  3.03it/s]  \n",
      "704it [01:12,  9.67it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 0.14844236, valid loss: 0.15665982, acc: 0.94480000, f1: 0.94470200, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:32<00:00,  3.05it/s]\n",
      "704it [01:12,  9.68it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 0.14830187, valid loss: 0.15665649, acc: 0.94477778, f1: 0.94466999, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:32<00:00,  3.05it/s]\n",
      "704it [01:12,  9.75it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train loss: 0.14828049, valid loss: 0.15665187, acc: 0.94474444, f1: 0.94463147, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [34:28<00:00,  3.06it/s]\n",
      "704it [01:12,  9.73it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 0.14810262, valid loss: 0.15661295, acc: 0.94478889, f1: 0.94468186, best_acc: 0.94490000\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1171/6329 [06:22<28:03,  3.06it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim, y_truth = batch\n",
    "        y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "        optimizer.zero_grad()\n",
    "                              \n",
    "        loss = loss_fn(y_pred, y_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "#         if epoch<2:\n",
    "#             scheduler_warm.step()\n",
    "# target.view(target.size(0), 1).long()\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    valid_preds_fold = np.zeros((valid_label.size(0), 2))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "                    \n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    acc, f1 = metric(valid_label, np.argmax(valid_preds_fold, axis=1))\n",
    "    if best_acc <= acc:\n",
    "        early_stop = 0\n",
    "        best_acc = acc\n",
    "        valid_best = valid_preds_fold\n",
    "        # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "        # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "        torch.save(model.state_dict(), train_root+'lstm_age_trf3.bin')\n",
    "    else:\n",
    "        early_stop += 1\n",
    "    print(\n",
    "        'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_acc: %.8f\\n' %\n",
    "        (epoch, train_loss, val_loss, acc, f1, best_acc))\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if early_stop >= patience:\n",
    "#         break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            if param_group['lr']>=3e-5:\n",
    "                param_group['lr'] *= 0.3\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(zip(np.argmax(valid_preds_fold, axis=1),np.array(valid_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=(a.loc[(a[0]==0)&(a[1]==1)].index.values)#0->1 6354 #1->0 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups: #0.9449\n",
    "        param_group['lr']=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2020.5.12\n",
    "0.39 0.92\n",
    "V1    age n_vocab不冻结0.39√    gender n_vocab 冻结 \n",
    "n_vocab在目前情况下看来不是效果很好\n",
    "V2    age all冻结 0.4528   gender all冻结0.9432\n",
    "V3    age cre与adv  lr-3 0.46 0.470 lr-4 0.4760   \n",
    "V4    age cre-adv-ind lr-4 0.4768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>351878 103064 665090 593698 1508864 1797787 17...</td>\n",
       "      <td>7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>3 11 11 23 29 49 49 49 54 54 82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>152519 151984 176984 12838 72773 64667 81234 7...</td>\n",
       "      <td>12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...</td>\n",
       "      <td>1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>161840 367084 36634 115761 73137 150407 41212 ...</td>\n",
       "      <td>22367_82_319_2 40491_34504_202_5 22338_2065_23...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>108656 849706 678427 9870 157180 94025 907546 ...</td>\n",
       "      <td>8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>123860 183003 40625 26793 71219 259607 167448 ...</td>\n",
       "      <td>30710_1896_238_2 29243_1987_26_2 23746_129_6_2...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>172004 237425 54100 417864 282643 30856 116356...</td>\n",
       "      <td>10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...</td>\n",
       "      <td>1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>271727 390953 914417 641757 50445 14993 793940...</td>\n",
       "      <td>10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>100456 464055 54150 316582 882346 882346 77124...</td>\n",
       "      <td>23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>273715 95215 146101 117043 840 366940 148209 7...</td>\n",
       "      <td>37660_\\N_322_18 22626_1062_238_2 20528_1492_32...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>250735 253460 333302 291416 231478 58631 11040...</td>\n",
       "      <td>30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...</td>\n",
       "      <td>2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        creative_id  \\\n",
       "0       3000001  351878 103064 665090 593698 1508864 1797787 17...   \n",
       "1       3000002  152519 151984 176984 12838 72773 64667 81234 7...   \n",
       "2       3000003  161840 367084 36634 115761 73137 150407 41212 ...   \n",
       "3       3000004  108656 849706 678427 9870 157180 94025 907546 ...   \n",
       "4       3000005  123860 183003 40625 26793 71219 259607 167448 ...   \n",
       "...         ...                                                ...   \n",
       "999995  3999996  172004 237425 54100 417864 282643 30856 116356...   \n",
       "999996  3999997  271727 390953 914417 641757 50445 14993 793940...   \n",
       "999997  3999998  100456 464055 54150 316582 882346 882346 77124...   \n",
       "999998  3999999  273715 95215 146101 117043 840 366940 148209 7...   \n",
       "999999  4000000  250735 253460 333302 291416 231478 58631 11040...   \n",
       "\n",
       "                                                  uni_col  \\\n",
       "0       7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...   \n",
       "1       12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...   \n",
       "2       22367_82_319_2 40491_34504_202_5 22338_2065_23...   \n",
       "3       8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...   \n",
       "4       30710_1896_238_2 29243_1987_26_2 23746_129_6_2...   \n",
       "...                                                   ...   \n",
       "999995  10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...   \n",
       "999996  10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...   \n",
       "999997  23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...   \n",
       "999998  37660_\\N_322_18 22626_1062_238_2 20528_1492_32...   \n",
       "999999  30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...   \n",
       "\n",
       "                                              click_times  \\\n",
       "0                                   1 1 1 1 1 1 1 1 1 1 1   \n",
       "1       1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3                 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "4       1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                   ...   \n",
       "999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...   \n",
       "999996            1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999997              1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999998  1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...   \n",
       "999999  2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                     time  \n",
       "0                         3 11 11 23 29 49 49 49 54 54 82  \n",
       "1       9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...  \n",
       "2       1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...  \n",
       "3       13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...  \n",
       "4       2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...  \n",
       "...                                                   ...  \n",
       "999995  1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...  \n",
       "999996  2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...  \n",
       "999997  4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...  \n",
       "999998  2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...  \n",
       "999999  1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_group = pd.read_csv(test_root+'test_trf.csv',index_col=0)\n",
    "test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1097/1000000 [00:00<03:08, 5302.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[111563, 1182, 46816, 21269, 2050, 1834, 1289, 1971, 102895, 37550, 4012, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [605, 185, 490, 8986, 711, 711, 158, 342, 6232, 6279, 868, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 11, 11, 23, 29, 49, 49, 49, 54, 54, 82, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [03:09<00:00, 5267.54it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1118466.15it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1232458.86it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1232211.20it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1223715.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 30s, sys: 31.8 s, total: 9min 2s\n",
      "Wall time: 8min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_examples, test_df = read_examples(test_group, is_training=False)\n",
    "test_features = convert_examples_to_features(test_examples, vocab, max_seq_length)\n",
    "\n",
    "test_input_cre = torch.tensor(np.array([test_feature.feature['creative']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_uni = torch.tensor(np.array([test_feature.feature['uni_col']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_clk = torch.tensor(np.array([test_feature.feature['click_times']  for test_feature in tqdm(test_features)]), dtype=torch.float32)\n",
    "test_input_tim = torch.tensor(np.array([test_feature.feature['time']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(test_input_cre, test_input_uni,test_input_clk,test_input_tim)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (embedding_cre): Embedding(3412773, 300)\n",
       "  (embedding_uni): Embedding(98846, 100)\n",
       "  (embeddingLN): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "  (postion_embedding): Positional_Encoding(\n",
       "    (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (embedding_pos): Embedding(92, 400)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attention): Multi_Head_Attention(\n",
       "      (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (attention): Scaled_Dot_Product_Attention()\n",
       "      (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (feed_forward): Position_wise_Feed_Forward(\n",
       "      (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (attention): Multi_Head_Attention(\n",
       "        (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (attention): Scaled_Dot_Product_Attention()\n",
       "        (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward): Position_wise_Feed_Forward(\n",
       "        (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "        (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(400, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=156, stride=156, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=1536, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.set_device(4)\n",
    "# model = RNN_Net(768,10)\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age_trf3.bin'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7813/7813 [04:37<00:00, 28.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 7, 2, ..., 2, 3, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_fold = np.zeros((len(test_df), 10))\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre, x_adv, x_ind= batch\n",
    "        y_pred = model(x_cre, x_adv, x_ind).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "test_preds_fold = np.argmax(test_preds_fold, axis=1)+1\n",
    "test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000002</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000003</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000004</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000005</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999998</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999999</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000000</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predicted_age  predicted_gender\n",
       "user_id                                 \n",
       "3000001              3                 1\n",
       "3000002              7                 2\n",
       "3000003              2                 2\n",
       "3000004              3                 1\n",
       "3000005              4                 1\n",
       "...                ...               ...\n",
       "3999996              3                 1\n",
       "3999997              2                 1\n",
       "3999998              2                 1\n",
       "3999999              3                 1\n",
       "4000000              5                 1\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission1.csv', index_col = 0 )\n",
    "submission.predicted_age = test_preds_fold\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log2(a+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([0],dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
