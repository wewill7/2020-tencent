{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train_semi_final/'\n",
    "test_root = './data/test/'\n",
    "# ad = pd.read_csv(train_root+'ad.csv')\n",
    "# click_log = pd.read_csv(train_root +'click_log.csv')\n",
    "# user = pd.read_csv(train_root+'user.csv')\n",
    "# Tclick_log = pd.read_csv(test_root +'click_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445721 4445721\n",
      "110810 110810\n"
     ]
    }
   ],
   "source": [
    "pre_embedding_cre = np.load(train_root+'creative_id_w2v_300d_f.npy')\n",
    "pre_vocab_cre = json.load(open(train_root+'creative_id_vocab_300d_f.json','r'))\n",
    "pre_vocab_cre.update({'_PAD_':len(pre_vocab_cre)})\n",
    "pre_embedding_cre = np.concatenate((pre_embedding_cre,np.zeros((1,300)) ))\n",
    "print(len(pre_embedding_cre),len(pre_vocab_cre))\n",
    "\n",
    "pre_embedding_uni = np.load(train_root+'uni_col_w2v_100d_f.npy')\n",
    "pre_vocab_uni = json.load(open(train_root+'uni_col_vocab_100d_f.json','r'))\n",
    "pre_vocab_uni.update({'_PAD_':len(pre_vocab_uni)})\n",
    "pre_embedding_uni = np.concatenate((pre_embedding_uni,np.zeros((1,100)) ))\n",
    "print(len(pre_embedding_uni),len(pre_vocab_uni))\n",
    "\n",
    "vocab = {\n",
    "    'creative':pre_vocab_cre,\n",
    "    'uni_col':pre_vocab_uni,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 1.88 s, total: 29.9 s\n",
      "Wall time: 29.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>821396 877468 209778 1683713 122032 71691 1940...</td>\n",
       "      <td>7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2</td>\n",
       "      <td>20 20 20 39 40 43 46 52 60 64 64 73 76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63441 155822 39714 609050 13069 441462 1266180...</td>\n",
       "      <td>22885_87_318_2 10686_80_238_2 18562_129_6_2 25...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>661347 808612 593522 825434 710859 726940 3920...</td>\n",
       "      <td>32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39588 589886 574787 1892854 1230094 2264105 31...</td>\n",
       "      <td>19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>296145 350759 24333 43235 852327 1054434 12964...</td>\n",
       "      <td>11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999996</td>\n",
       "      <td>190253 309607 1099 567833 571808 33159 1560316...</td>\n",
       "      <td>14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999997</td>\n",
       "      <td>20588 351431 15563 395549 169325 530723 43044 ...</td>\n",
       "      <td>11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999998</td>\n",
       "      <td>642652 932655 670 6508 944753 3507884 3123952 ...</td>\n",
       "      <td>29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>16 22 66 80 83 84 85 88 89 89 90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999999</td>\n",
       "      <td>69204 602554 498385 69204 2293419 3007031 2996...</td>\n",
       "      <td>24952_26858_60_3 28581_35561_\\N_4 28874_26858_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>3000000</td>\n",
       "      <td>44891 48221 17705 51330 192726 192492 192492 1...</td>\n",
       "      <td>20794_145_60_2 20794_145_60_2 17960_145_60_2 1...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                        creative_id  \\\n",
       "0              1  821396 877468 209778 1683713 122032 71691 1940...   \n",
       "1              2  63441 155822 39714 609050 13069 441462 1266180...   \n",
       "2              3  661347 808612 593522 825434 710859 726940 3920...   \n",
       "3              4  39588 589886 574787 1892854 1230094 2264105 31...   \n",
       "4              5  296145 350759 24333 43235 852327 1054434 12964...   \n",
       "...          ...                                                ...   \n",
       "2999995  2999996  190253 309607 1099 567833 571808 33159 1560316...   \n",
       "2999996  2999997  20588 351431 15563 395549 169325 530723 43044 ...   \n",
       "2999997  2999998  642652 932655 670 6508 944753 3507884 3123952 ...   \n",
       "2999998  2999999  69204 602554 498385 69204 2293419 3007031 2996...   \n",
       "2999999  3000000  44891 48221 17705 51330 192726 192492 192492 1...   \n",
       "\n",
       "                                                   uni_col  \\\n",
       "0        7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...   \n",
       "1        22885_87_318_2 10686_80_238_2 18562_129_6_2 25...   \n",
       "2        32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...   \n",
       "3        19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...   \n",
       "4        11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...   \n",
       "...                                                    ...   \n",
       "2999995  14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...   \n",
       "2999996  11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...   \n",
       "2999997  29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...   \n",
       "2999998  24952_26858_60_3 28581_35561_\\N_4 28874_26858_...   \n",
       "2999999  20794_145_60_2 20794_145_60_2 17960_145_60_2 1...   \n",
       "\n",
       "                                               click_times  \\\n",
       "0                                1 1 1 1 1 1 1 1 1 1 1 1 2   \n",
       "1        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "4        1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                    ...   \n",
       "2999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2999996  1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...   \n",
       "2999997                              1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999998              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999999  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                      time  age  gender  \n",
       "0                   20 20 20 39 40 43 46 52 60 64 64 73 76    4       1  \n",
       "1        10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...   10       1  \n",
       "2        12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...    7       2  \n",
       "3        8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...    5       1  \n",
       "4        3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...    4       1  \n",
       "...                                                    ...  ...     ...  \n",
       "2999995  1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...    4       2  \n",
       "2999996  3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...    2       2  \n",
       "2999997                   16 22 66 80 83 84 85 88 89 89 90    4       2  \n",
       "2999998  7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...    3       2  \n",
       "2999999  1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...    8       2  \n",
       "\n",
       "[3000000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_root+'train_trf.csv',index_col = 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, uid, creative, uni_col,click_times, time, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            id: Unique id for the example.\n",
    "            text: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.id = uid\n",
    "        self.text = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 feature,\n",
    "                 label\n",
    "                 ):\n",
    "        self.example_id = example_id\n",
    "        creative, uni_col, click_times, time = feature\n",
    "        self.feature = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "def read_examples(df, is_training):\n",
    "    if not is_training:\n",
    "        df['label'] = np.zeros(len(df), dtype=np.int64)\n",
    "    examples = []\n",
    "    for idex, row in df.iterrows():\n",
    "        if is_training:\n",
    "            label = row['age']\n",
    "        else:\n",
    "            label = row['label']\n",
    "        examples.append(InputExample(uid=idex, creative=row['creative_id'], uni_col =row['uni_col'], \n",
    "                                     click_times=row['click_times'], time = row['time'], label=label-1))\n",
    "    return examples, df\n",
    "\n",
    "def convert_examples_to_features(examples, word_to_id, max_seq_length):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        #!!!!!!!!!!!!!!!!!!!##\n",
    "        content=['creative','uni_col']\n",
    "        feature=[]\n",
    "        for onekind in content:\n",
    "            tokens_text = example.text[onekind].split()\n",
    "            tokens=[]\n",
    "            for token_text in tokens_text:\n",
    "                if token_text in word_to_id[onekind]:\n",
    "                    tokens.append(token_text)\n",
    "                else:\n",
    "                    tokens.append('_PAD_')\n",
    "            if len(tokens)>=max_seq_length:\n",
    "                tokens = tokens[:max_seq_length]\n",
    "            else:\n",
    "                tokens += ['_PAD_']*(max_seq_length-len(tokens))\n",
    "            token_ids = [word_to_id[onekind][token] for token in tokens]\n",
    "            feature.append(token_ids)\n",
    "        ###for click_times\n",
    "        tokens_text = example.text['click_times'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "            if int(token_text)<=4:\n",
    "                tokens.append(int(token_text))\n",
    "            else:\n",
    "                tokens.append(1)\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "        ###for time\n",
    "        tokens_text = example.text['time'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "                tokens.append(int(token_text))\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "            \n",
    "        \n",
    "        label = example.label\n",
    "\n",
    "        if example_index < 1:\n",
    "            print(example.id,'/n',feature,'/n',label)\n",
    "#             logger.info(\"*** Example ***\")\n",
    "#             logger.info(\"idx: {}\".format(example_index))\n",
    "#             logger.info(\"id: {}\".format(example.id))\n",
    "#             logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
    "#             logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
    "#             logger.info(\"input_mask: {}\".format(len(input_mask)))\n",
    "#             logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n",
    "#             logger.info(\"label: {}\".format(label))\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id=example.id,\n",
    "                feature= feature,\n",
    "                label=label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_class=10,dim=400,num_head=4,hidden=1024,dropout=0.1,max_seq_length=64):\n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_cre = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_cre,dtype=torch.float32), freeze=True)\n",
    "        self.embedding_uni = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_uni,dtype=torch.float32), freeze=True)\n",
    "        self.embeddingLN = nn.LayerNorm(dim, elementwise_affine=True)\n",
    "\n",
    "        self.postion_embedding = Positional_Encoding(dim)\n",
    "        self.encoder = Encoder(dim,num_head,hidden,dropout)#config.dim_model, config.num_head, config.hidden, config.dropout\n",
    "        self.encoders = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder)\n",
    "            # Encoder(config.dim_model, config.num_head, config.hidden, config.dropout)\n",
    "            for _ in range(1)])#config.num_encoder\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=400, hidden_size=768, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=0.5 )\n",
    "#         self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "        # self.fc1 = nn.Linear(config.pad_size * config.dim_model, config.num_classes)\n",
    "        # self.fc2 = nn.Linear(config.last_hidden, config.num_classes)\n",
    "        # self.fc1 = nn.Linear(config.dim_model, config.num_classes)\n",
    "        self.maxpool = nn.MaxPool1d(max_seq_length)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, cre, uni, clk, time):\n",
    "        x_cre = self.embedding_cre(cre)\n",
    "        x_uni = self.embedding_uni(uni)\n",
    "        x = torch.cat((x_cre, x_uni), 2)\n",
    "        x = self.embeddingLN(x)\n",
    "\n",
    "        out_trf = self.postion_embedding(x, time)\n",
    "        mask = clk.unsqueeze(1).expand(clk.size(0), clk.size(1), clk.size(1))#batch*seq*seq\n",
    "        for encoder in self.encoders:\n",
    "            out_trf = encoder(out_trf, mask)\n",
    "\n",
    "        pad = torch.clamp(clk,0,1).unsqueeze(2)        \n",
    "        out, _ = self.lstm(out_trf*pad)\n",
    "#         out = self.fc(out[:,-1,:])\n",
    "        # out = out.view(out.size(0), -1)#batch *seq*dim\n",
    "        # # out = torch.mean(out, 1)\n",
    "        # out = self.fc1(out)\n",
    "#         out = torch.cat((out_trf, out), 2)\n",
    "        out = out+(1-pad)*(-10000)\n",
    "        out = F.tanh(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.maxpool(out).squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.attention(x, mask)\n",
    "        out = self.feed_forward(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dim = dim_model\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "        pe = torch.tensor([[pos / (10000.0 ** (i // 2 * 2.0 / self.dim)) for i in range(self.dim)] for pos in range(92)],dtype=torch.float32)\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2])\n",
    "        self.embedding_pos = nn.Embedding.from_pretrained(pe, freeze=True)\n",
    "    def forward(self, x, time):\n",
    "\n",
    "        x_pos = self.embedding_pos(time)\n",
    "        out = x + x_pos\n",
    "        out = self.layer_norm(out)\n",
    "#         out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    '''Scaled Dot-Product Attention '''\n",
    "    def __init__(self):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__()\n",
    "#         self.atten_dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, Q, K, V, scale=None, mask =None):\n",
    "\n",
    "        attention = torch.matmul(Q, K.transpose(-1, -2))# scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "        if 1:  # TODO change this\n",
    "            # attention = attention.masked_fill_(mask == 0, -1e9)\n",
    "            attention = attention*torch.log2(1+mask)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        ###L dropout\n",
    "#         attention = self.atten_dropout(attention)\n",
    "        context = torch.matmul(attention, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, dropout=0.1):\n",
    "        super(Multi_Head_Attention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        assert dim_model % num_head == 0\n",
    "        self.dim_head = dim_model // self.num_head\n",
    "        self.fc_Q = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_K = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_V = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.fc = nn.Linear(num_head * self.dim_head, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        batch_size = x.size(0)\n",
    "        Q = self.fc_Q(x)\n",
    "        K = self.fc_K(x)\n",
    "        V = self.fc_V(x)\n",
    "        Q = Q.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        K = K.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "\n",
    "        if 1:  # TODO\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_head, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]  # TODO change this\n",
    "        scale = K.size(-1) ** -0.5  # 缩放因子\n",
    "        context = self.attention(Q, K, V, scale, mask)\n",
    "        #context: [batch_size x len_q x n_heads * d_v]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_head * self.num_head)\n",
    "        out = self.fc(context)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Position_wise_Feed_Forward(nn.Module):\n",
    "    def __init__(self, dim_model, hidden, dropout=0.0):\n",
    "        super(Position_wise_Feed_Forward, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.gelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 98\n",
    "batch_size = 128\n",
    "# tokenizer = jieba.lcut\n",
    "\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 20\n",
    "patience = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "# device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothLabelCritierion(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    1. Add label smoothing\n",
    "    2. Calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_smoothing=0.0):\n",
    "        super(SmoothLabelCritierion, self).__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.LogSoftmax = nn.LogSoftmax()\n",
    "\n",
    "        # When label smoothing is turned on, KL-divergence is minimized\n",
    "        # If label smoothing value is set to zero, the loss\n",
    "        # is equivalent to NLLLoss or CrossEntropyLoss.\n",
    "        if label_smoothing > 0:\n",
    "            self.criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "        else:\n",
    "            self.criterion = nn.NLLLoss()\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "\n",
    "    def _smooth_label(self, num_tokens):\n",
    "\n",
    "        one_hot = torch.randn(1, num_tokens)\n",
    "        one_hot.fill_(self.label_smoothing / (num_tokens - 1))\n",
    "        return one_hot\n",
    "\n",
    "    def _bottle(self, v):\n",
    "        return v.view(-1, v.size(2))\n",
    "\n",
    "    def forward(self, dec_outs, labels):\n",
    "        # Map the output to (0, 1)\n",
    "        scores = self.LogSoftmax(dec_outs)\n",
    "        # n_class\n",
    "        num_tokens = scores.size(-1)\n",
    "\n",
    "        gtruth = labels.view(-1)\n",
    "        if self.confidence < 1:\n",
    "            tdata = gtruth.detach()\n",
    "            one_hot = self._smooth_label(num_tokens)\n",
    "            if labels.is_cuda:\n",
    "                one_hot = one_hot.cuda()\n",
    "            tmp_ = one_hot.repeat(gtruth.size(0), 1)\n",
    "            tmp_.scatter_(1, tdata.unsqueeze(1), self.confidence)\n",
    "            gtruth = tmp_.detach()\n",
    "        loss = self.criterion(scores, gtruth)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810000, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(train, test_size=0.1, random_state=49, shuffle=True, stratify=train.age.values)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "valid_examples, valid_df = read_examples(valid, is_training=True)\n",
    "valid_features = convert_examples_to_features(valid_examples, vocab, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810000/810000 [00:00<00:00, 1377196.29it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1459770.95it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1288260.92it/s]\n",
      "100%|██████████| 810000/810000 [00:00<00:00, 1439208.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "valid_input_cre = torch.tensor(np.array([valid_feature.feature['creative'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_uni = torch.tensor(np.array([valid_feature.feature['uni_col'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_clk= torch.tensor(np.array([valid_feature.feature['click_times'] for valid_feature in valid_features]), dtype=torch.float32)\n",
    "valid_input_tim= torch.tensor(np.array([valid_feature.feature['time'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "valid_label = torch.tensor(np.array([valid_feature.label for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_input_cre,train_input_uni,train_input_clk,train_input_tim, train_label)\n",
    "valid_data = torch.utils.data.TensorDataset(valid_input_cre,valid_input_uni,valid_input_clk,valid_input_tim, valid_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(5)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = SmoothLabelCritierion(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler_warm= torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step:step/(2*len(train_loader)))\n",
    "\n",
    "best_acc = 0.\n",
    "valid_best = np.zeros((valid_label.size(0), 10))\n",
    "\n",
    "early_stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1742/3000000 [00:00<05:53, 8486.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[369522, 82667, 30791, 54327, 1122, 57, 17354, 2501, 3140, 1903, 18115, 1903, 150654, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [681, 3524, 2153, 2038, 1190, 42, 288, 2059, 880, 886, 847, 886, 17, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [20, 20, 20, 39, 40, 43, 46, 52, 60, 64, 64, 73, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000000/3000000 [06:27<00:00, 7734.26it/s] \n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1270075.47it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1367437.16it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1378473.71it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1357009.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###five fold\n",
    "####\n",
    "\n",
    "# train = pd.read_csv(train_root+'train_creative.csv',index_col = 0)\n",
    "\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "\n",
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "import gc\n",
    "del train\n",
    "del train_df\n",
    "del train_examples\n",
    "del train_features\n",
    "\n",
    "# del test_group\n",
    "# del test_df \n",
    "# del test_examples\n",
    "# del test_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================     fold 0        ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 17579/17579 [1:01:45<00:00,  4.74it/s]\n",
      "5860it [06:32, 14.94it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.08307474, valid loss: 1.17687860, acc: 0.51011867, f1: 0.50788913, best_f1: 1.17687860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17579/17579 [1:02:30<00:00,  4.69it/s]\n",
      "5860it [06:30, 14.99it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 1.07721962, valid loss: 1.17722935, acc: 0.51021733, f1: 0.50807024, best_f1: 1.17687860\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 14742/17579 [52:27<10:07,  4.67it/s] "
     ]
    }
   ],
   "source": [
    "###five fold\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=107)\n",
    "# off: out-of-fold\n",
    "# oof_test = np.zeros((100_0000, 10), dtype=np.float32)\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(train_label, train_label)):\n",
    "    if fold!=0:\n",
    "        continue\n",
    "\n",
    "    print('================     fold {}        ==============='.format(fold))\n",
    "    train_input_fold_cre = torch.tensor(train_input_cre[train_index], dtype=torch.long)\n",
    "    train_input_fold_uni = torch.tensor(train_input_uni[train_index], dtype=torch.long)\n",
    "    train_input_fold_clk = torch.tensor(train_input_clk[train_index], dtype=torch.float32)\n",
    "    train_input_fold_tim = torch.tensor(train_input_tim[train_index], dtype=torch.long)\n",
    "    train_label_fold = torch.tensor(train_label[train_index], dtype=torch.long)\n",
    "    \n",
    "    valid_input_fold_cre = torch.tensor(train_input_cre[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_uni = torch.tensor(train_input_uni[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_clk = torch.tensor(train_input_clk[valid_index], dtype=torch.float32)\n",
    "    valid_input_fold_tim = torch.tensor(train_input_tim[valid_index], dtype=torch.long)\n",
    "    valid_label_fold = torch.tensor(train_label[valid_index], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    train_data_fold  = torch.utils.data.TensorDataset(train_input_fold_cre,train_input_fold_uni,train_input_fold_clk,train_input_fold_tim, train_label_fold )\n",
    "    valid_data_fold  = torch.utils.data.TensorDataset(valid_input_fold_cre,valid_input_fold_uni,valid_input_fold_clk,valid_input_fold_tim,valid_label_fold )\n",
    "\n",
    "    train_loader_fold  = torch.utils.data.DataLoader(train_data_fold , batch_size=batch_size, shuffle=True)\n",
    "    valid_loader_fold  = torch.utils.data.DataLoader(valid_data_fold , batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "     \n",
    "        \n",
    "    torch.cuda.set_device(5)\n",
    "    model =  myModel(768,10,max_seq_length=max_seq_length)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age0.bin'))####TODO\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     loss_fn = SmoothLabelCritierion(label_smoothing=0.1)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.035},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    for param_group in optimizer.param_groups:####TODO\n",
    "        param_group['lr']=1e-6\n",
    "        \n",
    "    best_val = 10000.\n",
    "    valid_best = np.zeros((valid_label_fold.size(0), 10))\n",
    "\n",
    "    early_stop = 0    \n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    del train_input_cre\n",
    "    del train_input_uni\n",
    "    del train_input_clk\n",
    "    del train_input_tim\n",
    "    del pre_embedding_cre\n",
    "    del pre_embedding_uni\n",
    "    gc.collect()\n",
    "    for epoch in range(num_epochs):\n",
    "#         if epoch==16:\n",
    "#             model.load_state_dict(torch.load(train_root+'lstm_age0.bin'))\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr']=1e-6\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        for i, batch in enumerate(tqdm(train_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(y_pred, y_truth)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() / len(train_loader_fold)\n",
    "    # target.view(target.size(0), 1).long()\n",
    "        model.eval()\n",
    "        val_loss = 0.\n",
    "        valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "                y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "                val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "        if best_val >= val_loss:\n",
    "            early_stop = 0\n",
    "            best_val = val_loss\n",
    "            valid_best = valid_preds_fold\n",
    "            # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "            # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "            torch.save(model.state_dict(), train_root+'lstm_age0.bin')\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        print(\n",
    "            'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (epoch, train_loss, val_loss, acc, f1, best_val))\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if early_stop >= patience:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                if param_group['lr']>=3e-5:\n",
    "                    param_group['lr'] *= 0.3\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(param_group['lr'])\n",
    "\n",
    "            \n",
    "    test_preds_fold = np.zeros((100_0000, 10))\n",
    "    valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age0.bin'))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate( tqdm(test_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "    acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "    print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "                (acc, f1, best_val))\n",
    "   \n",
    "    \n",
    "    #oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "    oof_test += test_preds_fold#0.48427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1266it [01:18, 16.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0786b2306428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_cre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_uni\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_clk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tim\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_uni\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_clk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvalid_preds_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d1ba273f3cbf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cre, uni, clk, time)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_trf\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;31m#         out = self.fc(out[:,-1,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# out = out.view(out.size(0), -1)#batch *seq*dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "test_preds_fold = np.zeros((100_0000, 10))\n",
    "valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age0.bin', map_location={'cuda:5':'cuda:0'}))\n",
    "model.eval()\n",
    "# model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "        valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (acc, f1, best_val))\n",
    "\n",
    "\n",
    "#oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "# oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test = np.argmax(oof_test, axis=1)+1\n",
    "oof_test\n",
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = oof_test\n",
    "submission\n",
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_preds_fold).to_csv('five50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof0=pd.read_csv('five30.csv',index_col=0).values\n",
    "oof1=pd.read_csv('five31.csv',index_col=0).values\n",
    "oof2=pd.read_csv('five32.csv',index_col=0).values\n",
    "oof3=pd.read_csv('five33.csv',index_col=0).values\n",
    "oof4=pd.read_csv('five34.csv',index_col=0).values\n",
    "\n",
    "oof5=pd.read_csv('age5146.csv',index_col=0).values\n",
    "oof6=pd.read_csv('age5154.csv',index_col=0).values\n",
    "oof7=pd.read_csv('age5156.csv',index_col=0).values\n",
    "# oof0 = oof0*arr0\n",
    "# oof1 = oof1*arr1\n",
    "# oof2 = oof2*arr2\n",
    "# oof3 = oof3*arr3\n",
    "# oof4 = oof4*arr4\n",
    "# oof0 =oof0/np.sum(oof0,axis=1).reshape(-1,1)\n",
    "# oof1 =oof1/np.sum(oof1,axis=1).reshape(-1,1)\n",
    "# oof2 =oof2/np.sum(oof2,axis=1).reshape(-1,1)\n",
    "# oof3 =oof3/np.sum(oof3,axis=1).reshape(-1,1)\n",
    "# oof4 =oof4/np.sum(oof4,axis=1).reshape(-1,1)\n",
    "\n",
    "oof15=pd.read_csv('five20.csv',index_col=0).values\n",
    "oof16=pd.read_csv('five21.csv',index_col=0).values\n",
    "oof17=pd.read_csv('five22.csv',index_col=0).values\n",
    "oof18=pd.read_csv('five23.csv',index_col=0).values\n",
    "oof19=pd.read_csv('five24.csv',index_col=0).values\n",
    "# oof5 = oof5*arr5\n",
    "# oof6 = oof6*arr6\n",
    "# oof7 = oof7*arr7\n",
    "# oof8 = oof8*arr8\n",
    "# oof9 = oof9*arr9\n",
    "# oof5 =oof5/np.sum(oof5,axis=1).reshape(-1,1)\n",
    "# oof6 =oof6/np.sum(oof6,axis=1).reshape(-1,1)\n",
    "# oof7 =oof7/np.sum(oof7,axis=1).reshape(-1,1)\n",
    "# oof8 =oof8/np.sum(oof8,axis=1).reshape(-1,1)\n",
    "# oof9 =oof9/np.sum(oof9,axis=1).reshape(-1,1)\n",
    "\n",
    "oof10=pd.read_csv('five50.csv',index_col=0).values\n",
    "oof11=pd.read_csv('five51.csv',index_col=0).values\n",
    "oof12=pd.read_csv('five52.csv',index_col=0).values\n",
    "oof13=pd.read_csv('five53.csv',index_col=0).values\n",
    "oof14=pd.read_csv('five44.csv',index_col=0).values\n",
    "# oof10 = oof10*arr10\n",
    "# oof11 = oof11*arr11\n",
    "# oof12 = oof12*arr12\n",
    "# oof13 = oof13*arr13\n",
    "# oof14 = oof14*arr14\n",
    "# oof10 =oof10/np.sum(oof10,axis=1).reshape(-1,1)\n",
    "# oof11 =oof11/np.sum(oof11,axis=1).reshape(-1,1)\n",
    "# oof12 =oof12/np.sum(oof12,axis=1).reshape(-1,1)\n",
    "# oof13 =oof13/np.sum(oof13,axis=1).reshape(-1,1)\n",
    "# oof14 =oof14/np.sum(oof14,axis=1).reshape(-1,1)\n",
    "oof20=pd.read_csv('last0.csv',index_col=0).values\n",
    "oof21=pd.read_csv('last1.csv',index_col=0).values\n",
    "oof22=pd.read_csv('last2.csv',index_col=0).values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oof = (oof0+oof1+oof2+oof3+oof4+oof5+oof6+oof7+oof10+oof11+oof12+oof13+oof14+oof15+oof16+oof17+oof18+oof19+oof20+oof21+oof22)/21\n",
    "# oof = (oof10+oof11+oof12+oof13+oof14)/5\n",
    "oof_test = np.argmax(oof, axis=1)+1\n",
    "\n",
    "submission = pd.read_csv('./out/submission85.csv', index_col = 0 )\n",
    "submission.predicted_age = oof_test\n",
    "submission\n",
    "submission.to_csv('./out/submission955.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 2, ..., 2, 3, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weight1\n",
    "# arr0=[1.07, 1.01, 1.02, 0.99, 1.05, 1.0, 0.96, 0.86, 0.86, 1.08]\n",
    "# arr1=[0.93, 1.0, 1.0, 1.01, 1.0, 1.0, 0.92, 0.91, 1.03, 1.11]\n",
    "\n",
    "# arr2=[1.05, 1.16, 1.06, 1.0, 1.04, 1.01, 1.0, 0.9500000000000001, 1.0, 0.99]\n",
    "# arr3=[0.92, 1.11, 1.1, 1.02, 1.0, 0.99, 1.0, 0.88, 1.0, 1.1300000000000001]\n",
    "# arr4=[1.12,\n",
    "#  1.01,\n",
    "#  1.03,\n",
    "#  1.0,\n",
    "#  0.99,\n",
    "#  1.0,\n",
    "#  0.9500000000000001,\n",
    "#  0.9500000000000001,\n",
    "#  1.1,\n",
    "#  1.09]\n",
    "# # ###weight2\n",
    "# arr5=[1.1, 0.97, 1.0, 1.0, 1.0, 0.98, 0.89, 1.02, 1.0, 0.9400000000000001]\n",
    "\n",
    "# arr6=[0.99,1.09,1.03,0.98,1.0,0.9500000000000001,0.9500000000000001,1.0,1.01,1.0]\n",
    "# arr7=[0.99, 1.06, 1.02, 1.06, 1.05, 1.0, 1.04, 0.99, 0.92, 0.9400000000000001]\n",
    "# arr8=[0.8300000000000001, 0.97, 1.0, 1.0, 1.04, 1.0, 0.98, 0.97, 1.07, 0.99]\n",
    "# arr9=[1.08, 1.04, 1.0, 1.0, 1.03, 0.96, 0.89, 0.85, 0.9, 0.96]\n",
    "# ###weight3\n",
    "arr10=[0.8, 1.0, 1.04, 1.01, 1.03, 1.0, 1.02, 1.09, 1.0, 0.98]\n",
    "arr11=[0.8, 0.99, 1.02, 1.02, 0.97, 1.0, 0.93, 0.97, 1.0, 1.12]\n",
    "arr12=[0.62, 0.97, 1.05, 1.07, 1.04, 1.01, 0.88, 0.8200000000000001, 0.85, 0.85]\n",
    "arr13=[0.92, 1.04, 1.02, 0.99, 1.0, 0.99, 0.87, 0.8, 0.88, 0.96]\n",
    "arr14=[0.9, 1.1, 1.04, 1.0, 1.03, 1.0, 0.9, 0.88, 1.01, 1.1400000000000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "0.512505\n",
      "0.51251\n",
      "0.5125183333333333\n",
      "0.512535\n",
      "0.512545\n",
      "0.5125516666666666\n",
      "0.5125666666666666\n",
      "0.5125733333333333\n",
      "0.512595\n",
      "0.5126183333333333\n",
      "0.512655\n",
      "0.5127616666666667\n",
      "0.5127783333333333\n",
      "0.5127933333333333\n",
      "0.512835\n",
      "0.5128366666666667\n",
      "0.5128583333333333\n",
      "0.5128616666666667\n",
      "0.5128633333333333\n",
      "0.5128833333333334\n",
      "0.5129116666666667\n",
      "0.5129166666666667\n",
      "round:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8, 1.0, 1.04, 1.01, 1.03, 1.0, 1.02, 1.09, 1.0, 0.98]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num=10\n",
    "weights = [1.0]*class_num\n",
    "\n",
    "def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "    weight = init_weight.copy()\n",
    "    f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(\n",
    "        axis=1))\n",
    "    flag_score = 0\n",
    "    round_num = 1\n",
    "    while(flag_score != f_best):\n",
    "        print(\"round: \", round_num)\n",
    "        round_num += 1\n",
    "        flag_score = f_best\n",
    "        for c in range(class_num):\n",
    "            for n_w in range(0, 2000,10):\n",
    "                num = n_w * step\n",
    "                new_weight = weight.copy()\n",
    "                new_weight[c] = num\n",
    "\n",
    "                prob_df = raw_prob.copy()\n",
    "                prob_df = prob_df * np.array(new_weight)\n",
    "\n",
    "                f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(\n",
    "                    axis=1))\n",
    "                if f > f_best:\n",
    "                    weight = new_weight.copy()\n",
    "                    f_best = f\n",
    "                    print(f)\n",
    "    return weight\n",
    "search_weight(valid_label_fold,valid_preds_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6329 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 6329/6329 [21:40<00:00,  4.87it/s]  \n",
      "704it [00:45, 15.32it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.84381805, valid loss: 0.96334108, acc: 0.48791111, f1: 0.48512110, best_acc: 0.48791111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:36<00:00,  4.88it/s]\n",
      "704it [00:45, 15.31it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.83930354, valid loss: 0.96423356, acc: 0.48805556, f1: 0.48536756, best_acc: 0.48805556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:36<00:00,  4.88it/s]\n",
      "704it [00:46, 15.28it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 0.83684267, valid loss: 0.96509829, acc: 0.48822222, f1: 0.48562925, best_acc: 0.48822222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:36<00:00,  4.88it/s]\n",
      "704it [00:46, 15.30it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 0.83471344, valid loss: 0.96576512, acc: 0.48780000, f1: 0.48522301, best_acc: 0.48822222\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:35<00:00,  4.88it/s]\n",
      "704it [00:46, 15.30it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 0.83314430, valid loss: 0.96626772, acc: 0.48791111, f1: 0.48523907, best_acc: 0.48822222\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:40<00:00,  4.86it/s]  \n",
      "704it [00:46, 15.29it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train loss: 0.83180169, valid loss: 0.96678279, acc: 0.48754444, f1: 0.48489594, best_acc: 0.48822222\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6329/6329 [21:35<00:00,  4.89it/s]\n",
      "704it [00:46, 15.26it/s]\n",
      "  0%|          | 0/6329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 0.83044336, valid loss: 0.96735849, acc: 0.48758889, f1: 0.48502773, best_acc: 0.48822222\n",
      "\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1526/6329 [05:12<16:24,  4.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-243a11795418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#         if epoch<2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#             scheduler_warm.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim, y_truth = batch\n",
    "        y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "        optimizer.zero_grad()\n",
    "                                 \n",
    "        loss = loss_fn(y_pred, y_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "#         if epoch<2:\n",
    "#             scheduler_warm.step()\n",
    "# target.view(target.size(0), 1).long()\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    valid_preds_fold = np.zeros((valid_label.size(0), 10))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    acc, f1 = metric(valid_label, np.argmax(valid_preds_fold, axis=1))\n",
    "    if best_acc <= acc:\n",
    "        early_stop = 0\n",
    "        best_acc = acc\n",
    "        valid_best = valid_preds_fold\n",
    "        # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "        # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "        torch.save(model.state_dict(), train_root+'lstm_age_trf9.bin')\n",
    "    else:\n",
    "        early_stop += 1\n",
    "    print(\n",
    "        'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_acc: %.8f\\n' %\n",
    "        (epoch, train_loss, val_loss, acc, f1, best_acc))\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if early_stop >= patience:\n",
    "#         break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            if param_group['lr']>=3e-5:\n",
    "                param_group['lr'] *= 0.3\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:#copy4 0.4862,0.4884，#make pad 0.4885778 0.4906  ###lossfn 0.4882\n",
    "        param_group['lr']=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2020.5.12\n",
    "0.39 0.92\n",
    "V1    age n_vocab不冻结0.39√    gender n_vocab 冻结 \n",
    "n_vocab在目前情况下看来不是效果很好\n",
    "V2    age all冻结 0.4528   gender all冻结0.9432\n",
    "V3    age cre与adv  lr-3 0.46 0.470 lr-4 0.4760   \n",
    "V4    age cre-adv-ind lr-4 0.4768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>351878 103064 665090 593698 1508864 1797787 17...</td>\n",
       "      <td>7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>3 11 11 23 29 49 49 49 54 54 82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>152519 151984 176984 12838 72773 64667 81234 7...</td>\n",
       "      <td>12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...</td>\n",
       "      <td>1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>161840 367084 36634 115761 73137 150407 41212 ...</td>\n",
       "      <td>22367_82_319_2 40491_34504_202_5 22338_2065_23...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>108656 849706 678427 9870 157180 94025 907546 ...</td>\n",
       "      <td>8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>123860 183003 40625 26793 71219 259607 167448 ...</td>\n",
       "      <td>30710_1896_238_2 29243_1987_26_2 23746_129_6_2...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>172004 237425 54100 417864 282643 30856 116356...</td>\n",
       "      <td>10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...</td>\n",
       "      <td>1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>271727 390953 914417 641757 50445 14993 793940...</td>\n",
       "      <td>10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>100456 464055 54150 316582 882346 882346 77124...</td>\n",
       "      <td>23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>273715 95215 146101 117043 840 366940 148209 7...</td>\n",
       "      <td>37660_\\N_322_18 22626_1062_238_2 20528_1492_32...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>250735 253460 333302 291416 231478 58631 11040...</td>\n",
       "      <td>30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...</td>\n",
       "      <td>2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        creative_id  \\\n",
       "0       3000001  351878 103064 665090 593698 1508864 1797787 17...   \n",
       "1       3000002  152519 151984 176984 12838 72773 64667 81234 7...   \n",
       "2       3000003  161840 367084 36634 115761 73137 150407 41212 ...   \n",
       "3       3000004  108656 849706 678427 9870 157180 94025 907546 ...   \n",
       "4       3000005  123860 183003 40625 26793 71219 259607 167448 ...   \n",
       "...         ...                                                ...   \n",
       "999995  3999996  172004 237425 54100 417864 282643 30856 116356...   \n",
       "999996  3999997  271727 390953 914417 641757 50445 14993 793940...   \n",
       "999997  3999998  100456 464055 54150 316582 882346 882346 77124...   \n",
       "999998  3999999  273715 95215 146101 117043 840 366940 148209 7...   \n",
       "999999  4000000  250735 253460 333302 291416 231478 58631 11040...   \n",
       "\n",
       "                                                  uni_col  \\\n",
       "0       7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...   \n",
       "1       12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...   \n",
       "2       22367_82_319_2 40491_34504_202_5 22338_2065_23...   \n",
       "3       8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...   \n",
       "4       30710_1896_238_2 29243_1987_26_2 23746_129_6_2...   \n",
       "...                                                   ...   \n",
       "999995  10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...   \n",
       "999996  10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...   \n",
       "999997  23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...   \n",
       "999998  37660_\\N_322_18 22626_1062_238_2 20528_1492_32...   \n",
       "999999  30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...   \n",
       "\n",
       "                                              click_times  \\\n",
       "0                                   1 1 1 1 1 1 1 1 1 1 1   \n",
       "1       1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3                 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "4       1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                   ...   \n",
       "999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...   \n",
       "999996            1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999997              1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999998  1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...   \n",
       "999999  2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                     time  \n",
       "0                         3 11 11 23 29 49 49 49 54 54 82  \n",
       "1       9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...  \n",
       "2       1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...  \n",
       "3       13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...  \n",
       "4       2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...  \n",
       "...                                                   ...  \n",
       "999995  1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...  \n",
       "999996  2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...  \n",
       "999997  4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...  \n",
       "999998  2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...  \n",
       "999999  1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_group = pd.read_csv(test_root+'test_trf.csv',index_col=0)\n",
    "test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1368/1000000 [00:00<02:37, 6349.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[111563, 1182, 46816, 21269, 2050, 1834, 1289, 1971, 102895, 37550, 4012, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [605, 185, 490, 8986, 711, 711, 158, 342, 6232, 6279, 868, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 11, 11, 23, 29, 49, 49, 49, 54, 54, 82, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:10<00:00, 7643.22it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1198423.93it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1291016.27it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1291351.74it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1300995.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 44s, sys: 18.2 s, total: 7min 2s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_examples, test_df = read_examples(test_group, is_training=False)\n",
    "test_features = convert_examples_to_features(test_examples, vocab, max_seq_length)\n",
    "\n",
    "test_input_cre = torch.tensor(np.array([test_feature.feature['creative']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_uni = torch.tensor(np.array([test_feature.feature['uni_col']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_clk = torch.tensor(np.array([test_feature.feature['click_times']  for test_feature in tqdm(test_features)]), dtype=torch.float32)\n",
    "test_input_tim = torch.tensor(np.array([test_feature.feature['time']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(test_input_cre, test_input_uni,test_input_clk,test_input_tim)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (embedding_cre): Embedding(4445721, 300)\n",
       "  (embedding_uni): Embedding(110810, 100)\n",
       "  (embeddingLN): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "  (postion_embedding): Positional_Encoding(\n",
       "    (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (embedding_pos): Embedding(92, 400)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attention): Multi_Head_Attention(\n",
       "      (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (attention): Scaled_Dot_Product_Attention()\n",
       "      (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (feed_forward): Position_wise_Feed_Forward(\n",
       "      (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (attention): Multi_Head_Attention(\n",
       "        (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (attention): Scaled_Dot_Product_Attention()\n",
       "        (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward): Position_wise_Feed_Forward(\n",
       "        (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "        (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(400, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=98, stride=98, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(5)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age0.bin'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7813 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 7813/7813 [08:27<00:00, 15.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.26230884e-02, 2.86281198e-01, 5.99718392e-01, ...,\n",
       "        1.63569675e-05, 5.08086532e-06, 9.59346494e-07],\n",
       "       [1.63167006e-05, 1.59963076e-06, 3.22277515e-06, ...,\n",
       "        3.36288184e-01, 3.95302399e-04, 5.40568817e-06],\n",
       "       [1.18941453e-03, 9.20382515e-02, 1.57506570e-01, ...,\n",
       "        2.01478438e-03, 3.38752696e-04, 1.59271251e-04],\n",
       "       ...,\n",
       "       [2.15526447e-01, 7.37241387e-01, 4.69646454e-02, ...,\n",
       "        3.40048246e-07, 2.49450295e-07, 1.29994490e-07],\n",
       "       [4.21811506e-04, 3.20918649e-01, 6.77723527e-01, ...,\n",
       "        5.29480189e-07, 3.09092371e-07, 4.64222332e-08],\n",
       "       [2.33196537e-04, 1.08628592e-03, 4.88823792e-03, ...,\n",
       "        6.80395488e-06, 2.09470045e-07, 9.98468863e-08]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_fold = np.zeros((len(test_df), 10))\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre, x_uni, x_clk,x_tim= batch\n",
    "        y_pred = model(x_cre, x_uni, x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "# test_preds_fold = np.argmax(test_preds_fold, axis=1)+1\n",
    "test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000002</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000003</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000004</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000005</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999999</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predicted_age  predicted_gender\n",
       "user_id                                 \n",
       "3000001              3                 0\n",
       "3000002              7                 0\n",
       "3000003              2                 0\n",
       "3000004              3                 0\n",
       "3000005              4                 0\n",
       "...                ...               ...\n",
       "3999996              3                 0\n",
       "3999997              2                 0\n",
       "3999998              2                 0\n",
       "3999999              3                 0\n",
       "4000000              5                 0\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = test_preds_fold\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log2(a+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b882e48eecc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([0],dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
