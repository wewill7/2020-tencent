{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train_semi_final/'\n",
    "test_root = './data/test/'\n",
    "# ad = pd.read_csv(train_root+'ad.csv')\n",
    "# click_log = pd.read_csv(train_root +'click_log.csv')\n",
    "# user = pd.read_csv(train_root+'user.csv')\n",
    "# Tclick_log = pd.read_csv(test_root +'click_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445721 4445721\n",
      "110810 110810\n"
     ]
    }
   ],
   "source": [
    "pre_embedding_cre = np.load(train_root+'creative_id_w2v_300d_f.npy')\n",
    "pre_vocab_cre = json.load(open(train_root+'creative_id_vocab_300d_f.json','r'))\n",
    "pre_vocab_cre.update({'_PAD_':len(pre_vocab_cre)})\n",
    "pre_embedding_cre = np.concatenate((pre_embedding_cre,np.zeros((1,300)) ))\n",
    "print(len(pre_embedding_cre),len(pre_vocab_cre))\n",
    "\n",
    "pre_embedding_uni = np.load(train_root+'uni_col_w2v_100d_f.npy')\n",
    "pre_vocab_uni = json.load(open(train_root+'uni_col_vocab_100d_f.json','r'))\n",
    "pre_vocab_uni.update({'_PAD_':len(pre_vocab_uni)})\n",
    "pre_embedding_uni = np.concatenate((pre_embedding_uni,np.zeros((1,100)) ))\n",
    "print(len(pre_embedding_uni),len(pre_vocab_uni))\n",
    "\n",
    "vocab = {\n",
    "    'creative':pre_vocab_cre,\n",
    "    'uni_col':pre_vocab_uni,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 s, sys: 2.02 s, total: 30 s\n",
      "Wall time: 30 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>821396 877468 209778 1683713 122032 71691 1940...</td>\n",
       "      <td>7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2</td>\n",
       "      <td>20 20 20 39 40 43 46 52 60 64 64 73 76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63441 155822 39714 609050 13069 441462 1266180...</td>\n",
       "      <td>22885_87_318_2 10686_80_238_2 18562_129_6_2 25...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>661347 808612 593522 825434 710859 726940 3920...</td>\n",
       "      <td>32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39588 589886 574787 1892854 1230094 2264105 31...</td>\n",
       "      <td>19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>296145 350759 24333 43235 852327 1054434 12964...</td>\n",
       "      <td>11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2999996</td>\n",
       "      <td>190253 309607 1099 567833 571808 33159 1560316...</td>\n",
       "      <td>14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2999997</td>\n",
       "      <td>20588 351431 15563 395549 169325 530723 43044 ...</td>\n",
       "      <td>11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...</td>\n",
       "      <td>1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...</td>\n",
       "      <td>3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2999998</td>\n",
       "      <td>642652 932655 670 6508 944753 3507884 3123952 ...</td>\n",
       "      <td>29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>16 22 66 80 83 84 85 88 89 89 90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2999999</td>\n",
       "      <td>69204 602554 498385 69204 2293419 3007031 2996...</td>\n",
       "      <td>24952_26858_60_3 28581_35561_\\N_4 28874_26858_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>3000000</td>\n",
       "      <td>44891 48221 17705 51330 192726 192492 192492 1...</td>\n",
       "      <td>20794_145_60_2 20794_145_60_2 17960_145_60_2 1...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                        creative_id  \\\n",
       "0              1  821396 877468 209778 1683713 122032 71691 1940...   \n",
       "1              2  63441 155822 39714 609050 13069 441462 1266180...   \n",
       "2              3  661347 808612 593522 825434 710859 726940 3920...   \n",
       "3              4  39588 589886 574787 1892854 1230094 2264105 31...   \n",
       "4              5  296145 350759 24333 43235 852327 1054434 12964...   \n",
       "...          ...                                                ...   \n",
       "2999995  2999996  190253 309607 1099 567833 571808 33159 1560316...   \n",
       "2999996  2999997  20588 351431 15563 395549 169325 530723 43044 ...   \n",
       "2999997  2999998  642652 932655 670 6508 944753 3507884 3123952 ...   \n",
       "2999998  2999999  69204 602554 498385 69204 2293419 3007031 2996...   \n",
       "2999999  3000000  44891 48221 17705 51330 192726 192492 192492 1...   \n",
       "\n",
       "                                                   uni_col  \\\n",
       "0        7293_\\N_326_5 29455_\\N_106_5 9702_136_6_2 1466...   \n",
       "1        22885_87_318_2 10686_80_238_2 18562_129_6_2 25...   \n",
       "2        32974_36256_\\N_17 9877_40905_\\N_17 17018_1674_...   \n",
       "3        19451_1862_238_2 7976_\\N_25_18 13084_2625_248_...   \n",
       "4        11882_\\N_297_5 992_\\N_\\N_8 22885_87_318_2 9706...   \n",
       "...                                                    ...   \n",
       "2999995  14681_\\N_297_18 14681_\\N_6_18 6753_26926_60_3 ...   \n",
       "2999996  11016_49_6_2 23057_1674_322_2 10988_1261_6_2 9...   \n",
       "2999997  29053_1567_6_2 274_\\N_\\N_16 8058_1334_317_2 16...   \n",
       "2999998  24952_26858_60_3 28581_35561_\\N_4 28874_26858_...   \n",
       "2999999  20794_145_60_2 20794_145_60_2 17960_145_60_2 1...   \n",
       "\n",
       "                                               click_times  \\\n",
       "0                                1 1 1 1 1 1 1 1 1 1 1 1 2   \n",
       "1        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3        1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "4        1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                    ...   \n",
       "2999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2999996  1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 ...   \n",
       "2999997                              1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999998              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "2999999  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                      time  age  gender  \n",
       "0                   20 20 20 39 40 43 46 52 60 64 64 73 76    4       1  \n",
       "1        10 11 14 17 28 28 28 38 38 39 41 42 42 42 44 4...   10       1  \n",
       "2        12 13 14 14 14 17 19 22 31 36 37 44 47 47 50 5...    7       2  \n",
       "3        8 15 41 44 48 48 48 48 49 52 58 58 59 61 62 62...    5       1  \n",
       "4        3 13 14 15 20 21 24 25 27 28 29 30 32 32 35 35...    4       1  \n",
       "...                                                    ...  ...     ...  \n",
       "2999995  1 3 7 10 12 16 30 39 49 49 49 54 55 56 59 65 6...    4       2  \n",
       "2999996  3 3 5 5 6 8 10 11 14 18 19 19 20 21 22 26 27 2...    2       2  \n",
       "2999997                   16 22 66 80 83 84 85 88 89 89 90    4       2  \n",
       "2999998  7 9 19 32 63 65 67 69 75 75 75 75 76 76 79 79 ...    3       2  \n",
       "2999999  1 1 2 3 10 10 15 24 28 44 45 46 51 57 59 59 61...    8       2  \n",
       "\n",
       "[3000000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_root+'train_trf.csv',index_col = 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, uid, creative, uni_col,click_times, time, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            id: Unique id for the example.\n",
    "            text: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.id = uid\n",
    "        self.text = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 feature,\n",
    "                 label\n",
    "                 ):\n",
    "        self.example_id = example_id\n",
    "        creative, uni_col, click_times, time = feature\n",
    "        self.feature = {\n",
    "            'creative':creative,\n",
    "            'uni_col':uni_col,\n",
    "            'click_times':click_times,\n",
    "            'time':time\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "def read_examples(df, is_training):\n",
    "    if not is_training:\n",
    "        df['label'] = np.zeros(len(df), dtype=np.int64)\n",
    "    examples = []\n",
    "    for idex, row in df.iterrows():\n",
    "        if is_training:\n",
    "            label = row['age']\n",
    "        else:\n",
    "            label = row['label']\n",
    "        examples.append(InputExample(uid=idex, creative=row['creative_id'], uni_col =row['uni_col'], \n",
    "                                     click_times=row['click_times'], time = row['time'], label=label-1))\n",
    "    return examples, df\n",
    "\n",
    "def convert_examples_to_features(examples, word_to_id, max_seq_length):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        #!!!!!!!!!!!!!!!!!!!##\n",
    "        content=['creative','uni_col']\n",
    "        feature=[]\n",
    "        for onekind in content:\n",
    "            tokens_text = example.text[onekind].split()\n",
    "            tokens=[]\n",
    "            for token_text in tokens_text:\n",
    "                if token_text in word_to_id[onekind]:\n",
    "                    tokens.append(token_text)\n",
    "                else:\n",
    "                    tokens.append('_PAD_')\n",
    "            if len(tokens)>=max_seq_length:\n",
    "                tokens = tokens[:max_seq_length]\n",
    "            else:\n",
    "                tokens += ['_PAD_']*(max_seq_length-len(tokens))\n",
    "            token_ids = [word_to_id[onekind][token] for token in tokens]\n",
    "            feature.append(token_ids)\n",
    "        ###for click_times\n",
    "        tokens_text = example.text['click_times'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "            if int(token_text)<=4:\n",
    "                tokens.append(int(token_text))\n",
    "            else:\n",
    "                tokens.append(1)\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "        ###for time\n",
    "        tokens_text = example.text['time'].split()\n",
    "        tokens=[]\n",
    "        for token_text in tokens_text:\n",
    "                tokens.append(int(token_text))\n",
    "\n",
    "        if len(tokens)>=max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "        else:\n",
    "            tokens += [0]*(max_seq_length-len(tokens))\n",
    "        feature.append(tokens)\n",
    "            \n",
    "        \n",
    "        label = example.label\n",
    "\n",
    "        if example_index < 1:\n",
    "            print(example.id,'/n',feature,'/n',label)\n",
    "#             logger.info(\"*** Example ***\")\n",
    "#             logger.info(\"idx: {}\".format(example_index))\n",
    "#             logger.info(\"id: {}\".format(example.id))\n",
    "#             logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
    "#             logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
    "#             logger.info(\"input_mask: {}\".format(len(input_mask)))\n",
    "#             logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n",
    "#             logger.info(\"label: {}\".format(label))\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id=example.id,\n",
    "                feature= feature,\n",
    "                label=label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_class=10,dim=400,num_head=4,hidden=1024,dropout=0.1,max_seq_length=64):\n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_cre = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_cre,dtype=torch.float32), freeze=True)\n",
    "        self.embedding_uni = nn.Embedding.from_pretrained(torch.tensor(pre_embedding_uni,dtype=torch.float32), freeze=True)\n",
    "        self.embeddingLN = nn.LayerNorm(dim, elementwise_affine=True)\n",
    "\n",
    "        self.postion_embedding = Positional_Encoding(dim)\n",
    "        self.encoder = Encoder(dim,num_head,hidden,dropout)#config.dim_model, config.num_head, config.hidden, config.dropout\n",
    "        self.encoders = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder)\n",
    "            # Encoder(config.dim_model, config.num_head, config.hidden, config.dropout)\n",
    "            for _ in range(1)])#config.num_encoder\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=400, hidden_size=768, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=0.5 )\n",
    "#         self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "        # self.fc1 = nn.Linear(config.pad_size * config.dim_model, config.num_classes)\n",
    "        # self.fc2 = nn.Linear(config.last_hidden, config.num_classes)\n",
    "        # self.fc1 = nn.Linear(config.dim_model, config.num_classes)\n",
    "        self.maxpool = nn.MaxPool1d(max_seq_length)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, cre, uni, clk, time):\n",
    "        x_cre = self.embedding_cre(cre)\n",
    "        x_uni = self.embedding_uni(uni)\n",
    "        x = torch.cat((x_cre, x_uni), 2)\n",
    "        x = self.embeddingLN(x)\n",
    "\n",
    "        out_trf = self.postion_embedding(x, time)\n",
    "        mask = clk.unsqueeze(1).expand(clk.size(0), clk.size(1), clk.size(1))#batch*seq*seq\n",
    "        for encoder in self.encoders:\n",
    "            out_trf = encoder(out_trf, mask)\n",
    "\n",
    "        pad = torch.clamp(clk,0,1).unsqueeze(2)        \n",
    "        out, _ = self.lstm(out_trf*pad)\n",
    "#         out = self.fc(out[:,-1,:])\n",
    "        # out = out.view(out.size(0), -1)#batch *seq*dim\n",
    "        # # out = torch.mean(out, 1)\n",
    "        # out = self.fc1(out)\n",
    "#         out = torch.cat((out_trf, out), 2)\n",
    "        out = out+(1-pad)*(-10000)\n",
    "        out = F.tanh(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.maxpool(out).squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.attention(x, mask)\n",
    "        out = self.feed_forward(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dim = dim_model\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "        pe = torch.tensor([[pos / (10000.0 ** (i // 2 * 2.0 / self.dim)) for i in range(self.dim)] for pos in range(92)],dtype=torch.float32)\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2])\n",
    "        self.embedding_pos = nn.Embedding.from_pretrained(pe, freeze=True)\n",
    "    def forward(self, x, time):\n",
    "\n",
    "        x_pos = self.embedding_pos(time)\n",
    "        out = x + x_pos\n",
    "        out = self.layer_norm(out)\n",
    "#         out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    '''Scaled Dot-Product Attention '''\n",
    "    def __init__(self):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__()\n",
    "#         self.atten_dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, Q, K, V, scale=None, mask =None):\n",
    "\n",
    "        attention = torch.matmul(Q, K.transpose(-1, -2))# scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "        if 1:  # TODO change this\n",
    "            # attention = attention.masked_fill_(mask == 0, -1e9)\n",
    "            attention = attention*torch.log2(1+mask)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        ###L dropout\n",
    "#         attention = self.atten_dropout(attention)\n",
    "        context = torch.matmul(attention, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, dropout=0.1):\n",
    "        super(Multi_Head_Attention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        assert dim_model % num_head == 0\n",
    "        self.dim_head = dim_model // self.num_head\n",
    "        self.fc_Q = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_K = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_V = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.fc = nn.Linear(num_head * self.dim_head, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        batch_size = x.size(0)\n",
    "        Q = self.fc_Q(x)\n",
    "        K = self.fc_K(x)\n",
    "        V = self.fc_V(x)\n",
    "        Q = Q.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        K = K.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_head, self.dim_head).transpose(1, 2)\n",
    "\n",
    "        if 1:  # TODO\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_head, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]  # TODO change this\n",
    "        scale = K.size(-1) ** -0.5  # 缩放因子\n",
    "        context = self.attention(Q, K, V, scale, mask)\n",
    "        #context: [batch_size x len_q x n_heads * d_v]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_head * self.num_head)\n",
    "        out = self.fc(context)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Position_wise_Feed_Forward(nn.Module):\n",
    "    def __init__(self, dim_model, hidden, dropout=0.0):\n",
    "        super(Position_wise_Feed_Forward, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.gelu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x  # 残差连接\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 98\n",
    "batch_size = 128\n",
    "# tokenizer = jieba.lcut\n",
    "\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 20\n",
    "patience = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "# device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothLabelCritierion(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    1. Add label smoothing\n",
    "    2. Calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_smoothing=0.0):\n",
    "        super(SmoothLabelCritierion, self).__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.LogSoftmax = nn.LogSoftmax()\n",
    "\n",
    "        # When label smoothing is turned on, KL-divergence is minimized\n",
    "        # If label smoothing value is set to zero, the loss\n",
    "        # is equivalent to NLLLoss or CrossEntropyLoss.\n",
    "        if label_smoothing > 0:\n",
    "            self.criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "        else:\n",
    "            self.criterion = nn.NLLLoss()\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "\n",
    "    def _smooth_label(self, num_tokens):\n",
    "\n",
    "        one_hot = torch.randn(1, num_tokens)\n",
    "        one_hot.fill_(self.label_smoothing / (num_tokens - 1))\n",
    "        return one_hot\n",
    "\n",
    "    def _bottle(self, v):\n",
    "        return v.view(-1, v.size(2))\n",
    "\n",
    "    def forward(self, dec_outs, labels):\n",
    "        # Map the output to (0, 1)\n",
    "        scores = self.LogSoftmax(dec_outs)\n",
    "        # n_class\n",
    "        num_tokens = scores.size(-1)\n",
    "\n",
    "        gtruth = labels.view(-1)\n",
    "        if self.confidence < 1:\n",
    "            tdata = gtruth.detach()\n",
    "            one_hot = self._smooth_label(num_tokens)\n",
    "            if labels.is_cuda:\n",
    "                one_hot = one_hot.cuda()\n",
    "            tmp_ = one_hot.repeat(gtruth.size(0), 1)\n",
    "            tmp_.scatter_(1, tdata.unsqueeze(1), self.confidence)\n",
    "            gtruth = tmp_.detach()\n",
    "        loss = self.criterion(scores, gtruth)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(train, test_size=0.01, random_state=49, shuffle=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f1a6026c4941>\u001b[0m in \u001b[0;36mread_examples\u001b[0;34m(df, is_training)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3277\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   3229\u001b[0m         \u001b[0;31m# Need this first(ish) so that Sparse[datetime] is sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtensionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3231\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3232\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3233\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \"\"\"\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_pandas_abc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "valid_examples, valid_df = read_examples(valid, is_training=True)\n",
    "valid_features = convert_examples_to_features(valid_examples, vocab, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e02b64caae40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_input_cre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'creative'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_input_uni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uni_col'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_input_clk\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click_times'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_input_tim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "valid_input_cre = torch.tensor(np.array([valid_feature.feature['creative'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_uni = torch.tensor(np.array([valid_feature.feature['uni_col'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "valid_input_clk= torch.tensor(np.array([valid_feature.feature['click_times'] for valid_feature in valid_features]), dtype=torch.float32)\n",
    "valid_input_tim= torch.tensor(np.array([valid_feature.feature['time'] for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "valid_label = torch.tensor(np.array([valid_feature.label for valid_feature in valid_features]), dtype=torch.long)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_input_cre,train_input_uni,train_input_clk,train_input_tim, train_label)\n",
    "valid_data = torch.utils.data.TensorDataset(valid_input_cre,valid_input_uni,valid_input_clk,valid_input_tim, valid_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(5)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler_warm= torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step:step/(2*len(train_loader)))\n",
    "\n",
    "best_acc = 0.\n",
    "valid_best = np.zeros((valid_label.size(0), 10))\n",
    "\n",
    "early_stop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1736/3000000 [00:00<05:53, 8485.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[369522, 82667, 30791, 54327, 1122, 57, 17354, 2501, 3140, 1903, 18115, 1903, 150654, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [681, 3524, 2153, 2038, 1190, 42, 288, 2059, 880, 886, 847, 886, 17, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [20, 20, 20, 39, 40, 43, 46, 52, 60, 64, 64, 73, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000000/3000000 [06:22<00:00, 7848.19it/s] \n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1235917.99it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1349320.40it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1351752.45it/s]\n",
      "100%|██████████| 3000000/3000000 [00:02<00:00, 1342981.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###five fold\n",
    "####\n",
    "\n",
    "# train = pd.read_csv(train_root+'train_creative.csv',index_col = 0)\n",
    "\n",
    "train_examples, train_df = read_examples(train, is_training=True)\n",
    "train_features = convert_examples_to_features(train_examples, vocab, max_seq_length)\n",
    "\n",
    "train_input_cre = torch.tensor(np.array([train_feature.feature['creative'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_uni = torch.tensor(np.array([train_feature.feature['uni_col'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_input_clk= torch.tensor(np.array([train_feature.feature['click_times'] for train_feature in tqdm(train_features)]), dtype=torch.float32)\n",
    "train_input_tim= torch.tensor(np.array([train_feature.feature['time'] for train_feature in tqdm(train_features)]), dtype=torch.long)\n",
    "train_label = torch.tensor(np.array([train_feature.label for train_feature in train_features]), dtype=torch.long)\n",
    "\n",
    "import gc\n",
    "del train\n",
    "del train_df\n",
    "del train_examples\n",
    "del train_features\n",
    "\n",
    "# del test_group\n",
    "# del test_df \n",
    "# del test_examples\n",
    "# del test_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================     fold 2        ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 17579/17579 [59:40<00:00,  4.91it/s] \n",
      "5860it [06:18, 15.50it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.06832853, valid loss: 1.18088691, acc: 0.50904800, f1: 0.50654678, best_f1: 1.18088691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17579/17579 [59:32<00:00,  4.92it/s] \n",
      "5860it [06:18, 15.48it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 1.06533270, valid loss: 1.18127215, acc: 0.50919067, f1: 0.50676229, best_f1: 1.18088691\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17579/17579 [59:31<00:00,  4.92it/s] \n",
      "5860it [06:18, 15.50it/s]\n",
      "  0%|          | 0/17579 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 1.06176913, valid loss: 1.18236845, acc: 0.50880267, f1: 0.50658934, best_f1: 1.18088691\n",
      "\n",
      "1e-06\n",
      "1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 10959/17579 [37:06<22:20,  4.94it/s] "
     ]
    }
   ],
   "source": [
    "###five fold\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=107)\n",
    "# off: out-of-fold\n",
    "# oof_test = np.zeros((100_0000, 10), dtype=np.float32)\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(train_label, train_label)):\n",
    "    if fold!=2:\n",
    "        continue\n",
    "\n",
    "    print('================     fold {}        ==============='.format(fold))\n",
    "    train_input_fold_cre = torch.tensor(train_input_cre[train_index], dtype=torch.long)\n",
    "    train_input_fold_uni = torch.tensor(train_input_uni[train_index], dtype=torch.long)\n",
    "    train_input_fold_clk = torch.tensor(train_input_clk[train_index], dtype=torch.float32)\n",
    "    train_input_fold_tim = torch.tensor(train_input_tim[train_index], dtype=torch.long)\n",
    "    train_label_fold = torch.tensor(train_label[train_index], dtype=torch.long)\n",
    "    \n",
    "    valid_input_fold_cre = torch.tensor(train_input_cre[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_uni = torch.tensor(train_input_uni[valid_index], dtype=torch.long)\n",
    "    valid_input_fold_clk = torch.tensor(train_input_clk[valid_index], dtype=torch.float32)\n",
    "    valid_input_fold_tim = torch.tensor(train_input_tim[valid_index], dtype=torch.long)\n",
    "    valid_label_fold = torch.tensor(train_label[valid_index], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    train_data_fold  = torch.utils.data.TensorDataset(train_input_fold_cre,train_input_fold_uni,train_input_fold_clk,train_input_fold_tim, train_label_fold )\n",
    "    valid_data_fold  = torch.utils.data.TensorDataset(valid_input_fold_cre,valid_input_fold_uni,valid_input_fold_clk,valid_input_fold_tim,valid_label_fold )\n",
    "\n",
    "    train_loader_fold  = torch.utils.data.DataLoader(train_data_fold , batch_size=batch_size, shuffle=True)\n",
    "    valid_loader_fold  = torch.utils.data.DataLoader(valid_data_fold , batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "     \n",
    "    del train_input_cre\n",
    "    del train_input_uni\n",
    "    del train_input_clk\n",
    "    del train_input_tim\n",
    "    gc.collect()        \n",
    "    torch.cuda.set_device(1)\n",
    "    model =  myModel(768,10,max_seq_length=max_seq_length)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age2.bin'))####TODO\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     loss_fn = SmoothLabelCritierion(label_smoothing=0.1)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.035},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    ###!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!####\n",
    "    for param_group in optimizer.param_groups:####TODO\n",
    "        param_group['lr']=1e-6\n",
    "\n",
    "    best_val = 10000.\n",
    "    valid_best = np.zeros((valid_label_fold.size(0), 10))\n",
    "\n",
    "    early_stop = 0    \n",
    "    model.train()\n",
    "\n",
    "\n",
    "    del pre_embedding_cre\n",
    "    del pre_embedding_uni\n",
    "    gc.collect()\n",
    "    for epoch in range(num_epochs):\n",
    "#         if epoch==16:\n",
    "#             model.load_state_dict(torch.load(train_root+'lstm_age2.bin'))\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr']=1e-6\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        for i, batch in enumerate(tqdm(train_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(y_pred, y_truth)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() / len(train_loader_fold)\n",
    "    # target.view(target.size(0), 1).long()\n",
    "        model.eval()\n",
    "        val_loss = 0.\n",
    "        valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "                y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "                val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "        if best_val >= val_loss:\n",
    "            early_stop = 0\n",
    "            best_val =val_loss\n",
    "            valid_best = valid_preds_fold\n",
    "            # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "            # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "            torch.save(model.state_dict(), train_root+'lstm_age2.bin')\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        print(\n",
    "            'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (epoch, train_loss, val_loss, acc, f1, best_val))\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if early_stop >= patience:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                if param_group['lr']>=3e-5:\n",
    "                    param_group['lr'] *= 0.3\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(param_group['lr'])\n",
    "\n",
    "            \n",
    "    test_preds_fold = np.zeros((100_0000, 10))\n",
    "    valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "    model.load_state_dict(torch.load(train_root+'lstm_age2.bin'))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate( tqdm(test_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "    acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "    print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "                (acc, f1, best_val))\n",
    "   \n",
    "    \n",
    "    #oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "    oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "4688it [07:53,  9.89it/s]\n",
      "100%|██████████| 7813/7813 [13:12<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: best, acc: 0.51240500, f1: 0.50986182, best_f1: 0.90941125\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'oof_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f03df742260a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0moof_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_preds_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'oof_test' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "test_preds_fold = np.zeros((100_0000, 10))\n",
    "valid_preds_fold = np.zeros((valid_label_fold.size(0), 10))\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age2.bin', map_location={'cuda:2':'cuda:0'}))\n",
    "model.eval()\n",
    "# model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(valid_loader_fold)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader_fold)\n",
    "        valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim = batch\n",
    "        y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "acc, f1 = metric(valid_label_fold, np.argmax(valid_preds_fold, axis=1))\n",
    "print('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (acc, f1, best_val))\n",
    "\n",
    "\n",
    "#oof_test += test_preds_fold / 7 # uncomment this for 7 folds\n",
    "#     oof_test += test_preds_fold / 5 # comment this line when training for 7 folds\n",
    "\n",
    "\n",
    "# oof_test += test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "0.5107683333333334\n",
      "0.5107883333333333\n",
      "0.5108066666666666\n",
      "0.5108133333333333\n",
      "0.5108366666666667\n",
      "0.510855\n",
      "0.51087\n",
      "0.5108783333333333\n",
      "0.5108866666666667\n",
      "0.5109166666666667\n",
      "0.5109633333333333\n",
      "0.510985\n",
      "0.5110666666666667\n",
      "0.5110733333333334\n",
      "0.5111016666666667\n",
      "0.5111316666666667\n",
      "0.5111366666666667\n",
      "0.5111866666666667\n",
      "0.51121\n",
      "0.51127\n",
      "0.5113083333333334\n",
      "0.5113133333333333\n",
      "0.5113883333333333\n",
      "0.5114116666666667\n",
      "0.511415\n",
      "0.5114283333333334\n",
      "0.51144\n",
      "0.5114583333333333\n",
      "0.51146\n",
      "0.511465\n",
      "0.5114783333333334\n",
      "0.5114983333333334\n",
      "0.5115133333333334\n",
      "0.51153\n",
      "0.5115416666666667\n",
      "0.5115533333333333\n",
      "0.5115583333333333\n",
      "0.5115716666666666\n",
      "0.5115766666666667\n",
      "0.5115866666666666\n",
      "0.511595\n",
      "0.5116016666666666\n",
      "0.5116066666666667\n",
      "0.5116116666666667\n",
      "round:  2\n",
      "0.511615\n",
      "0.5116216666666666\n",
      "0.5116233333333333\n",
      "0.5116266666666667\n",
      "0.511635\n",
      "0.5116366666666666\n",
      "round:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.62, 0.97, 1.05, 1.07, 1.04, 1.01, 0.88, 0.8200000000000001, 0.85, 0.85]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num=10\n",
    "weights = [1.0]*class_num\n",
    "\n",
    "def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "    weight = init_weight.copy()\n",
    "    f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(\n",
    "        axis=1))\n",
    "    flag_score = 0\n",
    "    round_num = 1\n",
    "    while(flag_score != f_best):\n",
    "        print(\"round: \", round_num)\n",
    "        round_num += 1\n",
    "        flag_score = f_best\n",
    "        for c in range(class_num):\n",
    "            for n_w in range(0, 2000,10):\n",
    "                num = n_w * step\n",
    "                new_weight = weight.copy()\n",
    "                new_weight[c] = num\n",
    "\n",
    "                prob_df = raw_prob.copy()\n",
    "                prob_df = prob_df * np.array(new_weight)\n",
    "\n",
    "                f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(\n",
    "                    axis=1))\n",
    "                if f > f_best:\n",
    "                    weight = new_weight.copy()\n",
    "                    f_best = f\n",
    "                    print(f)\n",
    "    return weight\n",
    "search_weight(valid_label_fold,valid_preds_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test = np.argmax(oof_test, axis=1)+1\n",
    "oof_test\n",
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = oof_test\n",
    "submission\n",
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_preds_fold).to_csv('five52.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48811666666666664"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6961 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 6961/6961 [22:45<00:00,  5.10it/s]\n",
      "71it [00:04, 16.42it/s]\n",
      "  0%|          | 0/6961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.36532105, valid loss: 1.31319206, acc: 0.45222222, f1: 0.44348758, best_acc: 0.45222222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6961/6961 [22:28<00:00,  5.16it/s]\n",
      "71it [00:04, 15.85it/s]\n",
      "  0%|          | 0/6961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 1.28742605, valid loss: 1.28109355, acc: 0.46711111, f1: 0.45849083, best_acc: 0.46711111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6961/6961 [22:47<00:00,  5.09it/s]\n",
      "71it [00:04, 16.14it/s]\n",
      "  0%|          | 0/6961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 1.26148883, valid loss: 1.27118075, acc: 0.47288889, f1: 0.46804795, best_acc: 0.47288889\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3349/6961 [10:35<11:20,  5.31it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre,x_uni,x_clk,x_tim, y_truth = batch\n",
    "        y_pred = model( x_cre,x_uni,x_clk,x_tim)\n",
    "        optimizer.zero_grad()\n",
    "                                 \n",
    "        loss = loss_fn(y_pred, y_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "#         if epoch<2:\n",
    "#             scheduler_warm.step()\n",
    "# target.view(target.size(0), 1).long()\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    valid_preds_fold = np.zeros((valid_label.size(0), 10))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(valid_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x_cre,x_uni,x_clk,x_tim,  y_truth = batch\n",
    "            y_pred = model(x_cre,x_uni,x_clk,x_tim).detach()\n",
    "            val_loss += loss_fn(y_pred, y_truth).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    acc, f1 = metric(valid_label, np.argmax(valid_preds_fold, axis=1))\n",
    "    if best_acc <= acc:\n",
    "        early_stop = 0\n",
    "        best_acc = acc\n",
    "        valid_best = valid_preds_fold\n",
    "        # torch.save(model.state_dict(), 'model_fold_{}.bin'.format(fold))\n",
    "        # # torch.save(model, os.path.join(MODEL_PATH, 'lmodel.pkl'))\n",
    "        torch.save(model.state_dict(), train_root+'lstm_age_trf9.bin')\n",
    "    else:\n",
    "        early_stop += 1\n",
    "    print(\n",
    "        'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_acc: %.8f\\n' %\n",
    "        (epoch, train_loss, val_loss, acc, f1, best_acc))\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if early_stop >= patience:\n",
    "#         break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            if param_group['lr']>=3e-5:\n",
    "                param_group['lr'] *= 0.3\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:#copy4 0.4862,0.4884\n",
    "        param_group['lr']=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2020.5.12\n",
    "0.39 0.92\n",
    "V1    age n_vocab不冻结0.39√    gender n_vocab 冻结 \n",
    "n_vocab在目前情况下看来不是效果很好\n",
    "V2    age all冻结 0.4528   gender all冻结0.9432\n",
    "V3    age cre与adv  lr-3 0.46 0.470 lr-4 0.4760   \n",
    "V4    age cre-adv-ind lr-4 0.4768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>uni_col</th>\n",
       "      <th>click_times</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>351878 103064 665090 593698 1508864 1797787 17...</td>\n",
       "      <td>7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>3 11 11 23 29 49 49 49 54 54 82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>152519 151984 176984 12838 72773 64667 81234 7...</td>\n",
       "      <td>12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...</td>\n",
       "      <td>1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>161840 367084 36634 115761 73137 150407 41212 ...</td>\n",
       "      <td>22367_82_319_2 40491_34504_202_5 22338_2065_23...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>108656 849706 678427 9870 157180 94025 907546 ...</td>\n",
       "      <td>8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>123860 183003 40625 26793 71219 259607 167448 ...</td>\n",
       "      <td>30710_1896_238_2 29243_1987_26_2 23746_129_6_2...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>172004 237425 54100 417864 282643 30856 116356...</td>\n",
       "      <td>10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...</td>\n",
       "      <td>1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>271727 390953 914417 641757 50445 14993 793940...</td>\n",
       "      <td>10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>100456 464055 54150 316582 882346 882346 77124...</td>\n",
       "      <td>23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...</td>\n",
       "      <td>1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>273715 95215 146101 117043 840 366940 148209 7...</td>\n",
       "      <td>37660_\\N_322_18 22626_1062_238_2 20528_1492_32...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>250735 253460 333302 291416 231478 58631 11040...</td>\n",
       "      <td>30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...</td>\n",
       "      <td>2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        creative_id  \\\n",
       "0       3000001  351878 103064 665090 593698 1508864 1797787 17...   \n",
       "1       3000002  152519 151984 176984 12838 72773 64667 81234 7...   \n",
       "2       3000003  161840 367084 36634 115761 73137 150407 41212 ...   \n",
       "3       3000004  108656 849706 678427 9870 157180 94025 907546 ...   \n",
       "4       3000005  123860 183003 40625 26793 71219 259607 167448 ...   \n",
       "...         ...                                                ...   \n",
       "999995  3999996  172004 237425 54100 417864 282643 30856 116356...   \n",
       "999996  3999997  271727 390953 914417 641757 50445 14993 793940...   \n",
       "999997  3999998  100456 464055 54150 316582 882346 882346 77124...   \n",
       "999998  3999999  273715 95215 146101 117043 840 366940 148209 7...   \n",
       "999999  4000000  250735 253460 333302 291416 231478 58631 11040...   \n",
       "\n",
       "                                                  uni_col  \\\n",
       "0       7579_\\N_322_18 13084_1794_248_2 7000_1701_247_...   \n",
       "1       12993_1674_322_2 27800_\\N_24_18 24661_1687_5_2...   \n",
       "2       22367_82_319_2 40491_34504_202_5 22338_2065_23...   \n",
       "3       8520_1036_319_2 28323_\\N_40_18 2286_\\N_54_18 8...   \n",
       "4       30710_1896_238_2 29243_1987_26_2 23746_129_6_2...   \n",
       "...                                                   ...   \n",
       "999995  10985_1261_6_2 7725_1404_2_2 10987_1261_6_2 35...   \n",
       "999996  10986_\\N_6_12 16639_1246_81_2 15102_\\N_222_5 3...   \n",
       "999997  23365_\\N_27_18 28073_2344_167_2 10989_\\N_202_1...   \n",
       "999998  37660_\\N_322_18 22626_1062_238_2 20528_1492_32...   \n",
       "999999  30807_\\N_322_18 30817_\\N_322_18 1835_27031_317...   \n",
       "\n",
       "                                              click_times  \\\n",
       "0                                   1 1 1 1 1 1 1 1 1 1 1   \n",
       "1       1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3                 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "4       1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "...                                                   ...   \n",
       "999995  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 ...   \n",
       "999996            1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999997              1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "999998  1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 ...   \n",
       "999999  2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                                     time  \n",
       "0                         3 11 11 23 29 49 49 49 54 54 82  \n",
       "1       9 10 12 12 15 17 23 23 24 25 26 26 30 30 31 31...  \n",
       "2       1 3 3 3 3 4 4 11 11 15 19 21 27 37 38 43 55 58...  \n",
       "3       13 15 16 18 18 23 27 32 35 40 40 40 40 62 63 6...  \n",
       "4       2 3 6 7 7 8 9 13 26 27 28 33 35 38 51 55 62 65...  \n",
       "...                                                   ...  \n",
       "999995  1 1 2 5 8 10 12 24 28 28 30 34 35 35 40 40 40 ...  \n",
       "999996  2 10 17 18 18 20 30 30 45 47 48 57 59 65 67 82...  \n",
       "999997  4 9 12 15 17 22 25 32 39 46 51 61 65 68 68 75 ...  \n",
       "999998  2 2 2 3 6 7 8 12 19 20 21 26 26 26 26 29 30 31...  \n",
       "999999  1 2 3 3 4 4 4 7 10 10 12 13 13 15 17 21 21 22 ...  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_group = pd.read_csv(test_root+'test_trf.csv',index_col=0)\n",
    "test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1459/1000000 [00:00<02:23, 6953.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /n [[111563, 1182, 46816, 21269, 2050, 1834, 1289, 1971, 102895, 37550, 4012, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720, 4445720], [605, 185, 490, 8986, 711, 711, 158, 342, 6232, 6279, 868, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809, 110809], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 11, 11, 23, 29, 49, 49, 49, 54, 54, 82, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] /n -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:07<00:00, 7869.94it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1413710.58it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1287713.00it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1509600.96it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 1295348.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 38s, sys: 11.6 s, total: 6min 50s\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_examples, test_df = read_examples(test_group, is_training=False)\n",
    "test_features = convert_examples_to_features(test_examples, vocab, max_seq_length)\n",
    "\n",
    "test_input_cre = torch.tensor(np.array([test_feature.feature['creative']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_uni = torch.tensor(np.array([test_feature.feature['uni_col']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "test_input_clk = torch.tensor(np.array([test_feature.feature['click_times']  for test_feature in tqdm(test_features)]), dtype=torch.float32)\n",
    "test_input_tim = torch.tensor(np.array([test_feature.feature['time']  for test_feature in tqdm(test_features)]), dtype=torch.long)\n",
    "\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(test_input_cre, test_input_uni,test_input_clk,test_input_tim)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (embedding_cre): Embedding(4445721, 300)\n",
       "  (embedding_uni): Embedding(110810, 100)\n",
       "  (embeddingLN): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "  (postion_embedding): Positional_Encoding(\n",
       "    (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (embedding_pos): Embedding(92, 400)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attention): Multi_Head_Attention(\n",
       "      (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (attention): Scaled_Dot_Product_Attention()\n",
       "      (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (feed_forward): Position_wise_Feed_Forward(\n",
       "      (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (attention): Multi_Head_Attention(\n",
       "        (fc_Q): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_K): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (fc_V): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (attention): Scaled_Dot_Product_Attention()\n",
       "        (fc): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (feed_forward): Position_wise_Feed_Forward(\n",
       "        (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
       "        (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(400, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=98, stride=98, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "model = myModel(768,10,max_seq_length=max_seq_length)\n",
    "model.load_state_dict(torch.load(train_root+'lstm_age2.bin'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7813 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 7813/7813 [08:18<00:00, 15.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.53178200e-02, 4.65216488e-01, 4.67346281e-01, ...,\n",
       "        8.43096586e-06, 6.04892193e-06, 1.06397579e-06],\n",
       "       [2.47246699e-05, 1.55944019e-06, 1.67668350e-06, ...,\n",
       "        2.62217492e-01, 3.73706833e-04, 2.36679921e-06],\n",
       "       [3.37106315e-03, 2.95179278e-01, 2.62340367e-01, ...,\n",
       "        1.44700101e-03, 1.15024683e-04, 1.01335252e-04],\n",
       "       ...,\n",
       "       [1.54137745e-01, 7.48730004e-01, 9.67913121e-02, ...,\n",
       "        8.40928976e-07, 5.44834677e-07, 2.65863918e-07],\n",
       "       [1.04435324e-03, 3.30369204e-01, 6.67657614e-01, ...,\n",
       "        4.41217622e-07, 2.89706350e-07, 6.23693239e-08],\n",
       "       [1.21329802e-04, 1.10025145e-03, 6.08071312e-03, ...,\n",
       "        1.27125677e-05, 6.90671243e-07, 1.15046561e-07]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_fold = np.zeros((len(test_df), 10))\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate( tqdm(test_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_cre, x_uni, x_clk,x_tim= batch\n",
    "        y_pred = model(x_cre, x_uni, x_clk,x_tim).detach()\n",
    "        test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        \n",
    "# test_preds_fold = np.argmax(test_preds_fold, axis=1)+1\n",
    "test_preds_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000002</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000003</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000004</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000005</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999999</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000000</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predicted_age  predicted_gender\n",
       "user_id                                 \n",
       "3000001              3                 0\n",
       "3000002              7                 0\n",
       "3000003              2                 0\n",
       "3000004              3                 0\n",
       "3000005              4                 0\n",
       "...                ...               ...\n",
       "3999996              3                 0\n",
       "3999997              2                 0\n",
       "3999998              2                 0\n",
       "3999999              3                 0\n",
       "4000000              5                 0\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission2.csv', index_col = 0 )\n",
    "submission.predicted_age = test_preds_fold\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log2(a+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b882e48eecc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([0],dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
